{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math as mt\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def onehot(seq_list,alphabet):\n",
    "    length_seq = []\n",
    "    for i in range(0,len(seq_list)):\n",
    "        length_seq += [len(seq_list.iloc[i])]\n",
    "    max_len = max(length_seq)\n",
    "    onehot_seq = []\n",
    "    for i in range(0,len(seq_list)):\n",
    "        seq_str = seq_list.iloc[i]\n",
    "        seq_str = seq_str + '-'*(max_len - len(seq_str))\n",
    "        onehot_matrix = np.zeros((len(alphabet),max_len), dtype=int)\n",
    "        for j in range(0,len(seq_str)):\n",
    "            ind = alphabet.find(seq_str[j])\n",
    "            if ind!=-1:\n",
    "                onehot_matrix[ind,j] = 1 \n",
    "        onehot_matrix = onehot_matrix.transpose()\n",
    "        onehot_list = []\n",
    "        for k in range(0,len(seq_str)):\n",
    "            for j in range(0,len(alphabet)):\n",
    "                onehot_list += [onehot_matrix[k,j]]\n",
    "        onehot_seq.append(onehot_list)\n",
    "    return onehot_seq\n",
    "\n",
    "def ordinal(seq_list,alphabet):\n",
    "    length_seq = []\n",
    "    for i in range(0,len(seq_list)):\n",
    "        length_seq += [len(seq_list.iloc[i])]\n",
    "    max_len = max(length_seq)\n",
    "    ordinal_seq = []\n",
    "    for i in range(0,len(seq_list)):\n",
    "        seq_str = seq_list.iloc[i]\n",
    "        seq_str = seq_str + '-'*(max_len - len(seq_str))\n",
    "        ordinal_vec = []\n",
    "        for j in range(0,len(seq_str)):\n",
    "            ind = alphabet.find(seq_str[j])\n",
    "            if ind!=-1:\n",
    "                ordinal_vec += [ind+1]\n",
    "            else:\n",
    "                ordinal_vec += [0]\n",
    "        ordinal_seq.append(ordinal_vec)\n",
    "    return ordinal_seq\n",
    "\n",
    "\n",
    "def composition(seq_list,alphabet):\n",
    "    AAC_list = []\n",
    "    if type(seq_list)==str:\n",
    "        n=1\n",
    "    else:\n",
    "        n=len(seq_list)\n",
    "    for i in range(0,n):\n",
    "        AAC_vec = [0]*len(alphabet)\n",
    "        if type(seq_list)==str:\n",
    "            seq_str = seq_list\n",
    "        else:\n",
    "            seq_str = seq_list.iloc[i]\n",
    "        for j in range(0,len(seq_str)):\n",
    "            ind = alphabet.find(seq_str[j])\n",
    "            if ind!=-1:\n",
    "                AAC_vec[ind] = AAC_vec[ind]+1\n",
    "        N = len(seq_str)\n",
    "        AAC_vec = [AAC_vec[i]/N for i in range(0,len(AAC_vec))]\n",
    "        if type(seq_list)==str:\n",
    "            for k in range(0,len(AAC_vec)):\n",
    "                AAC_list += [AAC_vec[k]]\n",
    "        else:\n",
    "            AAC_list.append(AAC_vec)\n",
    "    return AAC_list\n",
    "\n",
    "\n",
    "def PC_prop(seq_list,alphabet,AAindex_loc,PCprop):\n",
    "    AAindex = pd.read_csv(AAindex_loc)\n",
    "    PCrow = AAindex.loc[AAindex['Property']==PCprop]\n",
    "    PC_list = []\n",
    "    for i in range(0,len(seq_list)):\n",
    "        PC_vec = []\n",
    "        seq_str = seq_list.iloc[i]\n",
    "        for j in range(0,len(seq_str)):\n",
    "            ind = alphabet.find(seq_str[j])\n",
    "            if ind!=-1:\n",
    "                PC_vec += PCrow[alphabet[ind]].tolist()\n",
    "        PC_list.append(PC_vec)\n",
    "    return PC_list\n",
    "\n",
    "def dipeptide_comp(seq_list,alphabet):\n",
    "    seq = seq_list\n",
    "    dipept_list = []\n",
    "    for k in range(0,len(seq)):\n",
    "        dipept_comp = np.zeros((len(alphabet),len(alphabet)),dtype=int)   ## rows=first aa, columns=second aa\n",
    "        dipept_quant = len(seq.iloc[k])-1\n",
    "        for j in range(0,len(seq.iloc[k])-1):\n",
    "            ind_first = alphabet.find(seq.iloc[k][j])\n",
    "            ind_second = alphabet.find(seq.iloc[k][j+1])\n",
    "            if ind_first!=-1 and ind_second!=-1:\n",
    "                dipept_comp[ind_first,ind_second] += 1\n",
    "        dipept_comp = dipept_comp/dipept_quant\n",
    "        dipept_comp = np.reshape(dipept_comp, len(alphabet)**2)\n",
    "        dipept_list.append(dipept_comp)\n",
    "    return dipept_list\n",
    "\n",
    "def digitalize(PC_list):\n",
    "    length_seq = []\n",
    "    for i in range(0,len(PC_list)):\n",
    "        length_seq += [len(PC_list[i])]\n",
    "    max_len = max(length_seq)\n",
    "    pad_power = mt.ceil(mt.log(max_len, 2))\n",
    "    pad_len = 2**pad_power\n",
    "    nyq_lim = pad_len/2\n",
    "    for i in range(0,len(PC_list)):\n",
    "        PC_list[i] = PC_list[i] + [0]*(pad_len - len(PC_list[i]))\n",
    "    digi_list = []\n",
    "    for i in range(0,len(PC_list)):\n",
    "        digi_vec = np.abs(sc.fft(PC_list[i]))\n",
    "        digi_vec = digi_vec[0:int(nyq_lim)]\n",
    "        digi_vec = [2*elem/pad_len for elem in digi_vec]\n",
    "        digi_list.append(digi_vec)\n",
    "    return digi_list\n",
    "    \n",
    "    \n",
    "\n",
    "class encoding:\n",
    "    \n",
    "    alphabet = 'ARNDCQEGHILKMFPSTWYV'\n",
    "    \n",
    "    def __init__(self,dataset_path):\n",
    "        if dataset_path.endswith('.csv'):\n",
    "            self.datasets = pd.read_csv(dataset_path)\n",
    "            self.subsetnames = os.path.basename(dataset_path)[0:-4]\n",
    "            self.setname = self.subsetnames[0].split(' ', 1)[0]\n",
    "        else:\n",
    "            print('ARCHIVO NO APLICABLE')\n",
    "                  \n",
    "    def remove_outliers(self):\n",
    "        col_names=list(self.datasets.columns.values)\n",
    "        if col_names[2]=='is_outlier':\n",
    "            outliers = self.datasets['is_outlier']\n",
    "            self.datasets = self.datasets[outliers != 1]\n",
    "            self.datasets.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    def one_hot_encoding(self,exportpath):\n",
    "        seq = self.datasets['sequence']\n",
    "        onehot_list = onehot(seq,self.alphabet)\n",
    "        col_names = list(self.datasets.columns.values)\n",
    "        columns = ['p'+str(k) for k in range(0,len(onehot_list[0]))]\n",
    "        rows = [k for k in range(0,len(seq))]\n",
    "        datacells = np.zeros((len(seq),len(onehot_list[0])))\n",
    "        for k in range(0,len(seq)):\n",
    "            for j in range(0,len(onehot_list[0])):\n",
    "                datacells[k,j] = onehot_list[k][j]         \n",
    "        df = pd.DataFrame(datacells,index=rows,columns=columns)\n",
    "        df.insert(0,col_names[1],self.datasets[col_names[1]])\n",
    "        if exportpath!='':\n",
    "            outfilename = exportpath + 'One_hot ' + self.subsetnames + '.csv'\n",
    "            outfile = open(outfilename, 'wb')\n",
    "            df.to_csv(outfilename, index = False, header = True, sep = ',', encoding = 'utf-8')\n",
    "            outfile.close()\n",
    "        else:\n",
    "            self.onehot_enc = df\n",
    "            return self.onehot_enc\n",
    "    \n",
    "    def ordinal_encoding(self,exportpath):\n",
    "        seq = self.datasets['sequence']\n",
    "        ordinal_list = ordinal(seq,self.alphabet)\n",
    "        columns = ['p'+str(k) for k in range(0,len(ordinal_list[0]))]\n",
    "        col_names = list(self.datasets.columns.values)\n",
    "        rows = [k for k in range(0,len(seq))]\n",
    "        datacells = np.zeros((len(seq),len(ordinal_list[0])))\n",
    "        for k in range(0,len(seq)):\n",
    "            for j in range(0,len(ordinal_list[0])):\n",
    "                datacells[k,j] = ordinal_list[k][j]         \n",
    "        df = pd.DataFrame(datacells,index=rows,columns=columns)\n",
    "        df.insert(0,col_names[1],self.datasets[col_names[1]])\n",
    "        if exportpath!='':\n",
    "            outfilename = exportpath + 'Ordinal ' + self.subsetnames + '.csv'\n",
    "            outfile = open(outfilename, 'wb')\n",
    "            df.to_csv(outfilename, index = False, header = True, sep = ',', encoding = 'utf-8')\n",
    "            outfile.close()\n",
    "        else:\n",
    "            self.ordinal_enc = df\n",
    "            return self.ordinal_enc\n",
    "    \n",
    "    def AAC_encoding(self,exportpath):\n",
    "        seq = self.datasets['sequence']\n",
    "        ACC_list = composition(seq,self.alphabet)\n",
    "        columns = [letter for letter in self.alphabet]\n",
    "        col_names = list(self.datasets.columns.values)\n",
    "        rows = [k for k in range(0,len(seq))]\n",
    "        datacells = np.zeros((len(seq),len(ACC_list[0])))\n",
    "        for k in range(0,len(seq)):\n",
    "            for j in range(0,len(ACC_list[0])):\n",
    "                datacells[k,j] = ACC_list[k][j]         \n",
    "        df = pd.DataFrame(datacells,index=rows,columns=columns)\n",
    "        df.insert(0,col_names[1],self.datasets[col_names[1]])\n",
    "        if exportpath!='':\n",
    "            outfilename = exportpath + 'AAC ' + self.subsetnames + '.csv'\n",
    "            outfile = open(outfilename, 'wb')\n",
    "            df.to_csv(outfilename, index = False, header = True, sep = ',', encoding = 'utf-8')\n",
    "            outfile.close()\n",
    "        else:\n",
    "            self.AAC_enc = df\n",
    "            return self.AAC_enc\n",
    "\n",
    "    def dipept_encoding(self,exportpath):\n",
    "        seq = self.datasets['sequence']\n",
    "        dipept_list = dipeptide_comp(seq,self.alphabet)\n",
    "        columns = []\n",
    "        for i in range(0,len(self.alphabet)):\n",
    "            for j in range(0,len(self.alphabet)):\n",
    "                dipeptide = self.alphabet[i] + self.alphabet[j]\n",
    "                columns += [dipeptide]\n",
    "        col_names = list(self.datasets.columns.values)\n",
    "        rows = [k for k in range(0,len(seq))]\n",
    "        datacells = np.zeros((len(seq),len(dipept_list[0])))\n",
    "        for k in range(0,len(seq)):\n",
    "            for j in range(0,len(dipept_list[0])):\n",
    "                datacells[k,j] = dipept_list[k][j]         \n",
    "        df = pd.DataFrame(datacells,index=rows,columns=columns)\n",
    "        df.insert(0,col_names[1],self.datasets[col_names[1]])\n",
    "        if exportpath!='':\n",
    "            outfilename = exportpath + 'dipeptide_comp ' + self.subsetnames + '.csv'\n",
    "            outfile = open(outfilename, 'wb')\n",
    "            df.to_csv(outfilename, index = False, header = True, sep = ',', encoding = 'utf-8')\n",
    "            outfile.close()\n",
    "        else:\n",
    "            self.dipept_enc = df\n",
    "            return self.dipept_enc\n",
    "        \n",
    "    def digit_encoding(self,exportpath,AAindex_loc,PCprop):\n",
    "        seq = self.datasets['sequence']\n",
    "        PC_list = PC_prop(seq,self.alphabet,AAindex_loc,PCprop)\n",
    "        digit_list = digitalize(PC_list)\n",
    "        columns = ['p'+str(k) for k in range(0,len(digit_list[0]))]\n",
    "        col_names = list(self.datasets.columns.values)\n",
    "        rows = [k for k in range(0,len(seq))]\n",
    "        datacells = np.zeros((len(seq),len(digit_list[0])))\n",
    "        for k in range(0,len(seq)):\n",
    "            for j in range(0,len(digit_list[0])):\n",
    "                datacells[k,j] = digit_list[k][j]         \n",
    "        df = pd.DataFrame(datacells,index=rows,columns=columns)\n",
    "        df.insert(0,col_names[1],self.datasets[col_names[1]])\n",
    "        if exportpath!='':\n",
    "            outfilename = exportpath + 'digitalization ' + PCprop + ' ' + self.subsetnames + '.csv'\n",
    "            outfile = open(outfilename, 'wb')\n",
    "            df.to_csv(outfilename, index = False, header = True, sep = ',', encoding = 'utf-8')\n",
    "            outfile.close()\n",
    "        else:\n",
    "            return df\n",
    "        \n",
    "\n",
    "    def fasta_conv(self,exportpath):\n",
    "        df = self.datasets \n",
    "        fasta_list = []\n",
    "        prob_type = self.datasets.columns[1]\n",
    "        if prob_type == 'class':\n",
    "            subsettypes = set(self.datasets['class'])\n",
    "            subsettypes = list(subsettypes)\n",
    "            for subset in subsettypes:\n",
    "                fasta_list = []\n",
    "                for i in range(0,len(df['sequence'])):\n",
    "                    if df['class'].iloc[i]==subset:\n",
    "                        fasta_list += ['>']\n",
    "                        fasta_list += [df['sequence'].iloc[i]]\n",
    "                rows = [i for i in range(0,len(fasta_list))]\n",
    "                fasta_df = pd.DataFrame(fasta_list,index=rows,columns=['sequence'])\n",
    "                outfilename = exportpath + 'fasta ' + str(subset) + ' ' + self.subsetnames + '.fasta'\n",
    "                with open(outfilename, 'w') as outfile:\n",
    "                    for row in fasta_df['sequence']:\n",
    "                        outfile.write(\"\".join(row)+'\\n')\n",
    "                outfile.close()\n",
    "        if prob_type == 'response':\n",
    "            for i in range(0,len(df['sequence'])):\n",
    "                fasta_list += ['>']\n",
    "                fasta_list += [df['sequence'].iloc[i]]\n",
    "            rows = [i for i in range(0,len(fasta_list))]\n",
    "            fasta_df = pd.DataFrame(fasta_list,index=rows,columns=['sequence'])\n",
    "            outfilename = exportpath + 'fasta ' + self.subsetnames + '.fasta'\n",
    "            with open(outfilename, 'w') as outfile:\n",
    "                for row in fasta_df['sequence']:\n",
    "                    outfile.write(\"\".join(row)+'\\n')\n",
    "            outfile.close()\n",
    "\n",
    "# El presente script puede ejecutarse por sí solo utilizando las funciones y métodos definidos.\n",
    "# Input: Archivo que se desea codificar, debe ser un .csv con 3 columnas: sequence, class o response, is_outlier.\n",
    "# Output: Archivo codificado según el método especificado, en formato .csv. Contiene class o response en la primera columna.\n",
    "\n",
    "## Instrucciones de uso:\n",
    "# 1. Declarar el archivo que se desea codificar\n",
    "# 2. Declarar la carpeta donde se desea guardar el archivo codificado\n",
    "# 3. En el caso de la digitalización, declarar el archivo que corresponde al AAindex, en .csv.\n",
    "# 4. Declarar el código de la propiedad fisicoquímica que se pretende emplear.\n",
    "# 5. Definir el conjunto de datos mediante una instancia de la clase \"encoding\"\n",
    "# 6. Emplear el método \"remove_outliers()\" para eliminar los outliers\n",
    "# 7. Utilizar los distintos métodos de codificación\n",
    "\n",
    "# Ejemplo (ajustar directorios según corresponda):\n",
    "\n",
    "inputpath = 'C:/Users/Kevin/Desktop/Datasets CSV/VaxinPad.csv'\n",
    "exportpath = 'C:/Users/Kevin/Desktop/'\n",
    "AAindex_path = 'C:/Users/Kevin/Desktop/AAindex.csv'\n",
    "props = ['PRAM900102','PRAM900103','COSI940101','HOPT810101','JOND750101','RADA880106','GRAR740103','FASG760101']\n",
    "\n",
    "Dataset = encoding(inputpath) #Define el conjunto de datos, el objeto posee los atributos \"subsetname y dataset\"\n",
    "Dataset.remove_outliers() #Elimina los outliers según la columna is_outlier\n",
    "#Dataset.digit_encoding(exportpath,AAindex_path,PCprop) #Retorna un archivo con el nombre \"digitalization ANDN920101 VaxinPad.csv\"\n",
    "#Dataset.one_hot_encoding(exportpath) #Retorna un archivo con el nombre \"One_hot VaxinPad.csv\"\n",
    "#Dataset.ordinal_encoding(exportpath) #Retorna un archivo con el nombre \"Ordinal VaxinPad.csv\"\n",
    "#Dataset.AAC_encoding(exportpath) #Retorna un archivo con el nombre \"AAC VaxinPad.csv\"\n",
    "Dataset.dipept_encoding(exportpath) #Retorna un archivo con el nombre \"dipeptide_comp VaxinPad.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "#for prop in props:\n",
    "#    print(prop)\n",
    "#    exportpath = exportloc + prop + '/' \n",
    "#    for root,dirs,files in os.walk(inputpath):\n",
    "#        for file in files:\n",
    "#            if file.endswith(\".csv\"):\n",
    "#                filename = inputpath + '/' + file\n",
    "#                print(filename)\n",
    "#                subset = encoding(filename)\n",
    "#                subset.remove_outliers()\n",
    "#                subset.digit_encoding(exportpath,AAindex_path,prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Kevin/Desktop/Datasets CSV//ACP-DL.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//AntiTb_primary.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//AntiTb_secondary.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//DBP.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//enantioselectivity.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//iACP.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//iAMP-2L_binary.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//iAMP-2L_multiclass.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//localization.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//Pop_ara.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//Pop_chlamy.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//Pop_yeast.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//QSP.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//RT_hela.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//RT_misc.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//RT_yeast.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//Solub.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//t50.csv\n",
      "C:/Users/Kevin/Desktop/Datasets CSV//VaxinPad.csv\n"
     ]
    }
   ],
   "source": [
    "#fastapath = 'C:/Users/Kevin/Desktop/fasta sequences/'\n",
    "#for root,dirs,files in os.walk(inputpath):\n",
    "#    for file in files:\n",
    "#        if file.endswith(\".csv\"):\n",
    "#            filename = inputpath + '/' + file\n",
    "#            print(filename)\n",
    "#            subset = encoding(filename)\n",
    "#            subset.remove_outliers()\n",
    "#            subset.fasta_conv(fastapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2,3],[4,5,6]])\n",
    "B =[]\n",
    "print(np.reshape(A,-1))\n",
    "B += [np.reshape(A,-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
