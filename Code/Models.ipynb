{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NeuralNetworksFourier.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOMgYwJkKXFch4ceOjY4Pz0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MHuHtKbreQUf","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","\n","!pip install -q sklearn\n","!pip install bayesian-optimization\n","!pip install PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"67a8ha6zZR0P","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599680325717,"user_tz":180,"elapsed":659,"user":{"displayName":"Kevin Vergara Valenzuela","photoUrl":"","userId":"16931137215428552402"}}},"source":["import os\n","import sys\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import math as mt\n","import time\n","import tensorflow.keras\n","import tensorflow.keras.initializers\n","from sklearn.model_selection import train_test_split, cross_validate\n","from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n","from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n","from sklearn.svm import SVC, SVR\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, r2_score, precision_score, recall_score, matthews_corrcoef, auc, roc_curve\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.losses import sparse_categorical_crossentropy\n","from tensorflow.keras.optimizers import Adam, Adamax, Adagrad, Adadelta\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.layers import LeakyReLU,PReLU, ELU\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer, BatchNormalization, concatenate, Input, Conv1D, MaxPooling1D, Flatten, LSTM, Bidirectional, TimeDistributed, Reshape, GlobalMaxPooling1D, GlobalMaxPool1D, AvgPool1D\n","from tensorflow.keras import regularizers\n","import time\n","import warnings\n","\n","documents_id = '1Z4mHE2N8Jy7Zjd4jZ973HtPHu8-JhhlQ'\n","documents_name = 'google_drive_documents_ids.csv'\n","\n","def r_square(y_true, y_pred):\n","  from keras import backend as K\n","  SS_res = K.sum(K.square(y_pred - y_true))\n","  SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n","  R2 = 1 - SS_res/(SS_tot + K.epsilon())\n","  return R2\n","\n","from keras import backend as K\n","\n","def recall_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def precision_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def f1_m(y_true, y_pred):\n","    precision = precision_m(y_true, y_pred)\n","    recall = recall_m(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","def matthews_correlation(y_true, y_pred):\n","    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n","    y_pred_neg = 1 - y_pred_pos\n","\n","    y_pos = K.round(K.clip(y_true, 0, 1))\n","    y_neg = 1 - y_pos\n","\n","    tp = K.sum(y_pos * y_pred_pos)\n","    tn = K.sum(y_neg * y_pred_neg)\n","\n","    fp = K.sum(y_neg * y_pred_pos)\n","    fn = K.sum(y_pos * y_pred_neg)\n","\n","    numerator = (tp * tn - fp * fn)\n","    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n","\n","    return numerator / (denominator + K.epsilon())"],"execution_count":79,"outputs":[]},{"cell_type":"code","metadata":{"id":"gUZUjIWSwvNP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599668511288,"user_tz":180,"elapsed":1401,"user":{"displayName":"Kevin Vergara Valenzuela","photoUrl":"","userId":"16931137215428552402"}}},"source":["def get_datasets(set_name,encoding,df):\n","  ids=[]\n","  filenames=[]\n","  PCprops = ['PRAM900102','PRAM900103','COSI940101','HOPT810101','JOND750101','RADA880106','GRAR740103','FASG760101']\n","  if encoding=='onehot':\n","    ids = [df[df['Unnamed: 0']==set_name]['One_hot'].iloc[0]]\n","    filenames = ['One_hot ' + set_name + '.csv']\n","  elif encoding=='ordinal':\n","    ids = [df[df['Unnamed: 0']==set_name]['Ordinal'].iloc[0]]\n","    filenames = ['Ordinal ' + set_name + '.csv']\n","  elif encoding=='AAC':\n","    ids = [df[df['Unnamed: 0']==set_name]['AAC'].iloc[0]]\n","    filenames = ['AAC ' + set_name + '.csv']\n","  elif encoding=='dipeptide_comp':\n","    ids = [df[df['Unnamed: 0']==set_name]['dipeptide_comp'].iloc[0]]\n","    filenames = ['dipeptide_comp ' + set_name + '.csv']\n","  elif encoding=='all digitalizations':\n","    for prop in PCprops:\n","      ids += [df[df['Unnamed: 0']==set_name]['digitalization ' + prop].iloc[0]]\n","      filenames += ['digitalization ' + prop + ' ' + set_name + '.csv']\n","  elif PCprops.count(encoding)==1:\n","    ids = [df[df['Unnamed: 0']==set_name]['digitalization ' + encoding].iloc[0]]\n","    filenames = ['digitalization ' + encoding + ' ' + set_name + '.csv']\n","  for i in range(0,len(ids)):\n","    documents_file = drive.CreateFile({'id':ids[i]})\n","    documents_file.GetContentFile(filenames[i])\n","  return ids, filenames"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"WDA38lpu313y","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599668513446,"user_tz":180,"elapsed":970,"user":{"displayName":"Kevin Vergara Valenzuela","photoUrl":"","userId":"16931137215428552402"}}},"source":["def read_dataframes(filenames):\n","  dfs = []\n","  for filename in filenames:\n","    df = pd.read_csv(filename)\n","    dfs += [df]\n","  return dfs\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"na9DlEB2-oOE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599675713012,"user_tz":180,"elapsed":1728,"user":{"displayName":"Kevin Vergara Valenzuela","photoUrl":"","userId":"16931137215428552402"}}},"source":["def knn_mod(dataframe, problemtype, kfold_CV=True, kmin=1, kmax=20, verb=1, K=1, target_names=['clase 0','clase 1']):\n","  df = dataframe\n","  if problemtype=='regression':\n","      df = df[df['response'].notna()]\n","  df = df.sample(frac=1).reset_index(drop=True)\n","  #samples = len(df['p0'])\n","\n","  verbosity = 1\n","  columns = df.columns.tolist()\n","  samples = len(df[columns[1]])\n","\n","  if problemtype=='multiclass':\n","    LE = LabelEncoder()\n","    numerics=LE.fit(df['class'].tolist())\n","    transformed = LE.transform(df['class'].tolist())\n","    df['class'] = transformed\n","\n","  if problemtype=='binary_class' and isinstance(df['class'].iloc[0],str):\n","    LE = LabelEncoder()\n","    numerics=LE.fit(df['class'].tolist())\n","    transformed = LE.transform(df['class'].tolist())\n","    df['class'] = transformed\n","\n","  # Split training and external validation set, establish number of k-folds for internal validation\n","  if samples > 100 and samples <= 500:\n","    dtrain, deval = train_test_split(df, test_size=0.3)\n","    num_folds = 10\n","  elif samples > 500:\n","    dtrain, deval = train_test_split(df, test_size=0.2)\n","    num_folds = 5\n","  elif samples <= 100:\n","    dtrain = df\n","    deval = []\n","    num_folds = samples\n","\n","  # Determine shape of the data\n","  input_shape = (len(columns)-1, )\n","\n","  # Define per-fold score containers\n","  acc_per_fold = []\n","  loss_per_fold = []\n","\n","  # Define the K-fold Cross Validator\n","  kfold = KFold(n_splits=num_folds, shuffle=True)\n","\n","  # Seperate inputs and target values\n","  target_train = dtrain.pop(columns[0])\n","  input_train = dtrain.astype('float64')/dtrain.max().max()\n","  target_test = deval.pop(columns[0])\n","  input_test = deval.astype('float64')/dtrain.max().max()\n","\n","  if kfold_CV==True:\n","    k_range = range(kmin, kmax+1)\n","    # K-fold Cross Validation model procedure\n","    if problemtype=='binary_class' or problemtype=='multiclass':\n","      k_scores = [[],[],[],[],[],[],[],[]]\n","      for k in k_range:\n","        knn = KNeighborsClassifier(n_neighbors=k)\n","        if problemtype=='binary_class':\n","          p = 'precision'\n","          r = 'recall'\n","          f1 = 'f1'\n","        elif problemtype=='multiclass':\n","          f1 = 'f1_weighted'\n","          p = 'precision_weighted'\n","          r = 'recall_weighted'\n","        scores = cross_validate(knn, input_train, target_train, cv=num_folds, scoring=('accuracy', p, r, f1), verbose=verb)\n","        k_scores[0] += [scores['test_accuracy'].mean()]\n","        k_scores[1] += [scores['test_accuracy'].std()]\n","        k_scores[2] += [scores['test_'+p].mean()]\n","        k_scores[3] += [scores['test_'+p].std()]\n","        k_scores[4] += [scores['test_'+r].mean()]\n","        k_scores[5] += [scores['test_'+r].std()]\n","        k_scores[6] += [scores['test_'+f1].mean()]\n","        k_scores[7] += [scores['test_'+f1].std()]\n","      score_dict = ['accuracy','precision','recall',f1]\n","      return k_scores\n","    elif problemtype=='regression':\n","      k_scores = [[],[],[],[]]\n","      for k in k_range:\n","        knn = KNeighborsRegressor(n_neighbors=k)\n","        scores = cross_validate(knn, input_train, target_train, cv=num_folds, scoring=('neg_mean_squared_error', 'r2'), verbose=verb)\n","        k_scores[0] += [scores['test_neg_mean_squared_error'].mean()]\n","        k_scores[1] += [scores['test_neg_mean_squared_error'].std()]\n","        k_scores[2] += [scores['test_r2'].mean()]\n","        k_scores[3] += [scores['test_r2'].std()]\n","      return k_scores\n","\n","  elif kfold_CV==False:\n","    target_test = np.array(target_test.tolist())\n","    if problemtype=='binary_class' or problemtype=='multiclass':\n","      if problemtype=='multiclass':\n","        c='balanced'\n","      else:\n","        c=None\n","      knn = KNeighborsClassifier(n_neighbors=K)\n","      knn.fit(input_train,target_train)\n","      y_pred = knn.predict(input_test)\n","      print(confusion_matrix(target_test,y_pred))\n","      score = accuracy_score(target_test,y_pred)\n","    elif problemtype=='regression':\n","      knn = KNeighborsRegressor(n_neighbors=K)\n","      knn.fit(input_train,target_train)\n","      y_pred = knn.predict(input_test)\n","      R2 = r2_score(target_test,y_pred)\n","      return R2\n","\n","\n","\n","def rf_mod(dataframe, problemtype, kfold_CV=True, ntree=200, bootstrap=False,\n","           max_features='auto', min_samples_leaf=1, min_samples_split=2,verb=1, n_jobs=None, class_weight=None):\n","  df = dataframe\n","  if problemtype=='regression':\n","      df = df[df['response'].notna()]\n","  #samples = len(df['p0'])\n","\n","  verbosity = 1\n","  columns = df.columns.tolist()\n","  samples = len(df[columns[1]])\n","\n","  if problemtype=='multiclass':\n","    LE = LabelEncoder()\n","    numerics=LE.fit(df['class'].tolist())\n","    transformed = LE.transform(df['class'].tolist())\n","    df['class'] = transformed\n","\n","  df = df.sample(frac=1).reset_index(drop=True)\n","\n","  # Split training and external validation set, establish number of k-folds for internal validation\n","  if samples > 100 and samples <= 500:\n","    dtrain, deval = train_test_split(df, test_size=0.3)\n","    num_folds = 10\n","  elif samples > 500:\n","    dtrain, deval = train_test_split(df, test_size=0.2)\n","    num_folds = 5\n","  elif samples <= 100:\n","    dtrain = df\n","    deval = []\n","    num_folds = samples\n","\n","  # Determine shape of the data\n","  input_shape = (len(columns)-1, )\n","\n","  # Define per-fold score containers\n","  acc_per_fold = []\n","  loss_per_fold = []\n","\n","  # Define the K-fold Cross Validator\n","  kfold = KFold(n_splits=num_folds, shuffle=True)\n","\n","  # Seperate inputs and target values\n","  target_train = dtrain.pop(columns[0])\n","  input_train = dtrain.astype('float64')/dtrain.max().max()\n","  target_test = deval.pop(columns[0])\n","  input_test = deval.astype('float64')/dtrain.max().max()\n","\n","  if kfold_CV==True:\n","    # K-fold Cross Validation model procedure\n","    if problemtype=='binary_class' or problemtype=='multiclass':\n","      rf_scores = [[],[],[],[],[],[],[],[]]\n","      rf = RandomForestClassifier(n_estimators=ntree, min_samples_split=min_samples_split,\n","                                    min_samples_leaf=min_samples_leaf, bootstrap=bootstrap, max_features=max_features, class_weight=class_weight)\n","      if problemtype=='binary_class':\n","        p = 'precision'\n","        r = 'recall'\n","        f1 = 'f1'\n","      elif problemtype=='multiclass':\n","        f1 = 'f1_weighted'\n","        p = 'precision_weighted'\n","        r = 'recall_weighted'\n","      scores = cross_validate(rf, input_train, target_train, cv=num_folds, scoring=('accuracy', p, r, f1),verbose=verb, n_jobs=n_jobs)\n","      rf_scores[0] += [scores['test_accuracy'].mean()]\n","      rf_scores[1] += [scores['test_accuracy'].std()]\n","      rf_scores[2] += [scores['test_'+p].mean()]\n","      rf_scores[3] += [scores['test_'+p].std()]\n","      rf_scores[4] += [scores['test_'+r].mean()]\n","      rf_scores[5] += [scores['test_'+r].std()]\n","      rf_scores[6] += [scores['test_'+f1].mean()]\n","      rf_scores[7] += [scores['test_'+f1].std()]\n","      return rf_scores\n","    elif problemtype=='regression':\n","      rf_scores = [[],[],[],[]]\n","      rf = RandomForestRegressor(n_estimators=ntree, min_samples_split=min_samples_split,\n","                                    min_samples_leaf=min_samples_leaf, bootstrap=bootstrap, max_features=max_features)\n","      scores = cross_validate(rf, input_train, target_train, cv=num_folds, scoring=('neg_mean_squared_error', 'r2'), verbose=verb, n_jobs=n_jobs)\n","      rf_scores[0] += [scores['test_neg_mean_squared_error'].mean()]\n","      rf_scores[1] += [scores['test_neg_mean_squared_error'].std()]\n","      rf_scores[2] += [scores['test_r2'].mean()]\n","      rf_scores[3] += [scores['test_r2'].std()]\n","      return rf_scores\n","\n","  elif kfold_CV==False:\n","    target_test = np.array(target_test.tolist())\n","    if problemtype=='binary_class' or problemtype=='multiclass':\n","      if problemtype=='multiclass':\n","        c='balanced'\n","      else:\n","        c=None\n","      rf = RandomForestClassifier(n_estimators=ntree, min_samples_split=min_samples_split,\n","                                    min_samples_leaf=min_samples_leaf, bootstrap=bootstrap, max_features=max_features)\n","      rf.fit(input_train,target_train)\n","      y_pred = rf.predict(input_test)\n","      print('y_pred:')\n","      print(y_pred)\n","      print('target_test:')\n","      print(target_test)\n","      score = accuracy_score(target_test,y_pred)\n","      return score\n","    elif problemtype=='regression':\n","      rf = RandomForestRegressor(n_estimators=ntree, min_samples_split=min_samples_split,\n","                                    min_samples_leaf=min_samples_leaf, bootstrap=bootstrap, max_features=max_features)\n","      rf.fit(input_train,target_train)\n","      y_pred = rf.predict(input_test)\n","      R2 = r2_score(target_test,y_pred)\n","      return R2\n","\n","\n","\n","def svm_mod(dataframe, problemtype, kfold_CV=True, C=1, kernel='rbf', gamma='scale', verb=1, n_jobs=None):\n","  df = dataframe\n","  if problemtype=='regression':\n","      df = df[df['response'].notna()]\n","  df = df.sample(frac=1).reset_index(drop=True)\n","  #samples = len(df['p0'])\n","\n","  verbosity = 1\n","  columns = df.columns.tolist()\n","  samples = len(df[columns[1]])\n","\n","  if problemtype=='multiclass':\n","    LE = LabelEncoder()\n","    numerics=LE.fit(df['class'].tolist())\n","    transformed = LE.transform(df['class'].tolist())\n","    df['class'] = transformed\n","\n","  # Split training and external validation set, establish number of k-folds for internal validation\n","  if samples > 100 and samples <= 500:\n","    dtrain, deval = train_test_split(df, test_size=0.3)\n","    num_folds = 10\n","  elif samples > 500:\n","    dtrain, deval = train_test_split(df, test_size=0.2)\n","    num_folds = 5\n","  elif samples <= 100:\n","    dtrain = df\n","    deval = []\n","    num_folds = samples\n","\n","  # Determine shape of the data\n","  input_shape = (len(columns)-1, )\n","\n","  # Define per-fold score containers\n","  acc_per_fold = []\n","  loss_per_fold = []\n","\n","  # Define the K-fold Cross Validator\n","  kfold = KFold(n_splits=num_folds, shuffle=True)\n","\n","  # Seperate inputs and target values\n","  target_train = dtrain.pop(columns[0])\n","  input_train = dtrain.astype('float64')/dtrain.max().max()\n","  target_test = deval.pop(columns[0])\n","  input_test = deval.astype('float64')/dtrain.max().max()\n","\n","  if kfold_CV==True:\n","    if problemtype=='binary_class' or problemtype=='multiclass':\n","      sv_scores = [[],[],[],[],[],[],[],[]]\n","      sv = SVC(C=C, kernel=kernel, gamma=gamma, verbose=verb, class_weight='balanced')\n","      if problemtype=='binary_class':\n","        p = 'precision'\n","        r = 'recall'\n","        f1 = 'f1'\n","      elif problemtype=='multiclass':\n","        f1 = 'f1_weighted'\n","        p = 'precision_weighted'\n","        r = 'recall_weighted'\n","      scores = cross_validate(sv, input_train, target_train, cv=num_folds, scoring=('accuracy', p, r, f1),verbose=verb, n_jobs=n_jobs)\n","      sv_scores[0] += [scores['test_accuracy'].mean()]\n","      sv_scores[1] += [scores['test_accuracy'].std()]\n","      sv_scores[2] += [scores['test_'+p].mean()]\n","      sv_scores[3] += [scores['test_'+p].std()]\n","      sv_scores[4] += [scores['test_'+r].mean()]\n","      sv_scores[5] += [scores['test_'+r].std()]\n","      sv_scores[6] += [scores['test_'+f1].mean()]\n","      sv_scores[7] += [scores['test_'+f1].std()]\n","      return sv_scores\n","    elif problemtype=='regression':\n","      sv_scores = [[],[],[],[]]\n","      sv = SVR(C=C, kernel=kernel, gamma=gamma, verbose=verb)\n","      scores = cross_validate(sv, input_train, target_train, cv=num_folds, scoring=('neg_mean_squared_error', 'r2'), verbose=verb, n_jobs=n_jobs)\n","      sv_scores[0] += [scores['test_neg_mean_squared_error'].mean()]\n","      sv_scores[1] += [scores['test_neg_mean_squared_error'].std()]\n","      sv_scores[2] += [scores['test_r2'].mean()]\n","      sv_scores[3] += [scores['test_r2'].std()]\n","      return sv_scores\n","\n","  elif kfold_CV==False:\n","    target_test = np.array(target_test.tolist())\n","    if problemtype=='binary_class' or problemtype=='multiclass':\n","      if problemtype=='multiclass':\n","        c='balanced'\n","      else:\n","        c=None\n","      sv = SVC(C=C, kernel=kernel, gamma=gamma, verbose=verb, class_weight=c)\n","      sv.fit(input_train,target_train)\n","      y_pred = sv.predict(input_test)\n","      score = accuracy_score(target_test,y_pred)\n","      return score\n","    elif problemtype=='regression':\n","      sv = SVR(C=C, kernel=kernel, gamma=gamma, verbose=verb)\n","      sv.fit(input_train,target_train)\n","      y_pred = sv.predict(input_test)\n","      R2 = r2_score(target_test,y_pred)\n","      return R2\n","\n"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4U0-eN4Qa4h","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599683692578,"user_tz":180,"elapsed":1072,"user":{"displayName":"Kevin Vergara Valenzuela","photoUrl":"","userId":"16931137215428552402"}}},"source":["\n","def fftpredict(dataframe, modeltype, problemtype, kfold_CV=True, dropout=0.2, lr=1e-4, loss_class='sparse_categorical_crossentropy', \n","               loss_reg='mse', stopmetric='val_loss', patience=200, epochs=1000, batch_size=32,\n","               optimizer=Adam, metrics=['accuracy'], min_delta=1e-3):\n","\n","  df = dataframe\n","  if problemtype=='regression':\n","      df = df[df['response'].notna()]\n","  df = df.sample(frac=1).reset_index(drop=True)\n","  #samples = len(df['p0'])\n","\n","  verbosity = 1\n","  columns = df.columns.tolist()\n","  samples = len(df[columns[1]])\n","\n","  if df.columns[0]=='class':\n","    no_outputs = len(df['class'].unique())\n","  elif df.columns[0]=='response':\n","    no_outputs = 1\n","\n","  if problemtype=='multiclass':\n","    LE = LabelEncoder()\n","    numerics=LE.fit(df['class'].tolist())\n","    transformed = LE.transform(df['class'].tolist())\n","    df['class'] = transformed\n","\n","  # Split training and external validation set, establish number of k-folds for internal validation\n","  if samples > 100 and samples <= 500:\n","    dtrain, deval = train_test_split(df, test_size=0.3)\n","    num_folds = 10\n","  elif samples > 500:\n","    dtrain, deval = train_test_split(df, test_size=0.2)\n","    num_folds = 5\n","  elif samples <= 100:\n","    dtrain = df\n","    deval = []\n","    num_folds = samples\n","\n","  # Determine shape of the data\n","  input_shape = (len(columns)-1, )\n","\n","  # Define per-fold score containers\n","  acc_per_fold = []\n","  loss_per_fold = []\n","\n","  # Define the K-fold Cross Validator\n","  kfold = KFold(n_splits=num_folds, shuffle=True)\n","\n","  # Seperate inputs and target values\n","  target_train = dtrain.pop(columns[0])\n","  input_train = dtrain.astype('float64')/dtrain.max().max()\n","  target_eval = deval.pop(columns[0])\n","  input_eval = deval.astype('float64')/dtrain.max().max()\n","\n","\n","  def generate_model(dropout,modeltype,problemtype):\n","    if modeltype=='ANN':\n","      inp = Input(shape=input_shape)\n","      model = Dense(256, activation='relu')(inp)\n","      model = Dropout(dropout)(model)\n","      #model = BatchNormalization()(model)\n","      model = Dense(128, activation='relu')(model)\n","      model = Dense(16, activation='relu')(model) \n","      model = Dropout(dropout)(model)\n","    elif modeltype=='LSTM':\n","      inp = Input(shape=(dtrain.shape[1],1))\n","      model = Bidirectional(LSTM(64, return_sequences =True, dropout=dropout))(inp)\n","      model = Dense(16, activation='relu')(model)\n","      model = Dropout(dropout)(model)\n","    elif modeltype=='CNN':\n","      inp = Input(shape=(dtrain.shape[1],1))\n","      model = Conv1D(filters=256, kernel_size=3, activation='relu')(inp)\n","      model = MaxPooling1D(pool_size=2)(model)\n","      model = Dropout(dropout)(model)\n","      model = Conv1D(filters=128, kernel_size=3, activation='relu')(model)\n","      model = MaxPooling1D(pool_size=2)(model)\n","      model = Dropout(dropout)(model)\n","      model = Flatten()(model)\n","      model = Dense(16, activation='relu')(model)\n","    if problemtype=='binary_class':\n","      model = Dense(2)(model)\n","      out = Activation('softmax')(model)\n","    elif problemtype=='multiclass':\n","      model = Dense(6)(model)\n","      out = Activation('softmax')(model)\n","    elif problemtype=='regression':\n","      out = Dense(1)(model)\n","    final = Model(inputs=[inp], outputs=[out])\n","    return final    \n","\n","  def evaluate_complete_model(modeltype, problemtype, kfold_CV, dropout, lr,\n","                              loss_class, loss_reg, stopmetric, patience, epochs, batch_size, optimizer, metrics, min_delta):\n","    batch_size = batch_size\n","    epochs_needed = []\n","    num = 0\n","    acc_per_fold = [] #acc or R2\n","    loss_per_fold = []\n","    start_time = time.time()\n","\n","    if kfold_CV==True:\n","      # K-fold Cross Validation model procedure\n","      fold_no = 1\n","      for train, internal_test in kfold.split(input_train, target_train):\n","        num+=1\n","\n","        # Model architect and hyperparameters establishment\n","        model = generate_model(dropout,modeltype,problemtype)\n","        if problemtype=='binary_class' or problemtype=='multiclass':\n","          loss=loss_class\n","        elif problemtype=='regression':\n","          loss=loss_reg\n","        if stopmetric=='val_r_square':\n","          mode = 'max'\n","        else:\n","          mode = 'auto'\n","        model.compile(loss=loss, optimizer=optimizer(lr=lr), metrics=metrics)\n","        monitor = EarlyStopping(monitor=stopmetric, min_delta=min_delta, \n","        patience=patience, verbose=0, mode=mode, restore_best_weights=True)\n","\n","        # Define training and validation subset within specific kfold set\n","        x_train = input_train.iloc[train]\n","        y_train = target_train.iloc[train]\n","        x_test = input_train.iloc[internal_test]\n","        y_test = target_train.iloc[internal_test]\n","\n","        # Generate a print\n","        print('------------------------------------------------------------------------')\n","        print(f'Training for fold {fold_no} ...')\n","\n","        # Train on the kfold sample\n","        model.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor], epochs=epochs, batch_size=batch_size, verbose=verbosity)\n","        epochs_end = monitor.stopped_epoch\n","        epochs_needed.append(epochs_end)\n","\n","        # Generate generalization metrics\n","        scores = model.evaluate(x_test, y_test, verbose=0)\n","        if problemtype=='regression':\n","          print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}')\n","          C = 1\n","        else:\n","          print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n","          C = 100\n","        acc_per_fold.append(scores[1] * C)\n","        loss_per_fold.append(scores[0])\n","\n","        # Increase fold number\n","        fold_no = fold_no + 1\n","\n","      time_took = time.time() - start_time\n","      print(f'time took for kfold_CV: {time_took}')\n","\n","      # Provide average scores      \n","      m1 = np.mean(loss_per_fold)\n","      m2 = np.mean(acc_per_fold)\n","      m3 = np.mean(epochs_needed)\n","      m1dev = np.std(loss_per_fold)\n","      m2dev = np.std(acc_per_fold)\n","      m3dev = np.std(epochs_needed)\n","      scores2 = model.evaluate(input_eval,target_eval)\n","      if problemtype=='regression':\n","        print(f'loss: {m1} +- {m1dev}, error: {m2} +- {m2dev}, epochs: {m3} +- {m3dev}, test error: {scores2[1]}')\n","      else:\n","        print(f'loss: {m1} +- {m1dev}, accuracy: {m2} +- {m2dev}, epochs: {m3} +- {m3dev}, test acc: {scores2[1]*100}')\n","      tensorflow.keras.backend.clear_session()\n","      stat = [m1,m1dev,m2,m2dev,m3,m3dev]\n","      return stat\n","\n","    elif kfold_CV==False:\n","      start_time = time.time()\n","      model = generate_model(dropout,modeltype,problemtype)\n","      if problemtype=='binary_class' or problemtype=='multiclass':\n","        loss=loss_class\n","      elif problemtype=='regression':\n","        loss=loss_reg\n","      model.compile(loss=loss, optimizer=optimizer(lr=lr), metrics=metrics)\n","      monitor = EarlyStopping(monitor=stopmetric, min_delta=min_delta, \n","                              patience=patience, verbose=1, mode='auto', restore_best_weights=True)\n","      x_train = input_train\n","      y_train = target_train\n","      x_test = input_eval\n","      y_test = target_eval\n","\n","      class_weight = {0: 1/0.203,\n","                      1: 1/0.037,\n","                      2: 1/0.096,\n","                      3: 1/0.023,\n","                      4: 1/0.033,\n","                      5: 1/0.609}\n","\n","      history = model.fit(x=x_train,y=y_train,validation_data=(x_test,y_test), callbacks=[monitor], epochs=epochs, batch_size=batch_size, verbose=verbosity, class_weight=class_weight)\n","\n","      y_pred = model.predict(x_test)\n","      #y_pred = np.array([round(y_pred[i,1]) for i in range(0,len(y_pred[:,1]))]).transpose()\n","      y_pred2 = []\n","      for i in range(0,len(y_pred[:,0])):\n","        ind = y_pred[i,:].tolist().index(max(y_pred[i,:].tolist()))\n","        y_pred2 += [ind]\n","      y_pred = np.array(y_pred2).transpose()\n","      #print(y_pred)\n","      y_pred_keras = model.predict(x_test)\n","      fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras[:,1])\n","      #model.evaluate(x_test, y_test, verbose=0)\n","      from sklearn.metrics import auc\n","      auc_keras = auc(fpr_keras, tpr_keras)\n","      plt.figure(1)\n","      plt.plot([0, 1], [0, 1], 'k--')\n","      plt.plot(fpr_keras, tpr_keras, label='AUC = {:.3f})'.format(auc_keras))\n","      plt.grid()\n","      plt.xlabel('False positive rate', fontsize=12)\n","      plt.ylabel('True positive rate',fontsize=12)\n","      plt.title('Curva ROC para DBP', fontsize=14)\n","\n","      plt.legend(loc='best')\n","      plt.show()\n","      #print(confusion_matrix(y_test,y_pred))\n","      A = [fpr_keras, tpr_keras]\n","      return A\n","\n","      #time_took = time.time() - start_time\n","      #print(f'time took for training on whole set: {time_took}')\n","\n","  A = evaluate_complete_model(modeltype, problemtype, kfold_CV, dropout, lr, \n","                              loss_class, loss_reg, stopmetric, patience, epochs, batch_size, optimizer, metrics, min_delta)\n","  return A"],"execution_count":128,"outputs":[]},{"cell_type":"code","metadata":{"id":"igJakdELEnMh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599680233569,"user_tz":180,"elapsed":748,"user":{"displayName":"Kevin Vergara Valenzuela","photoUrl":"","userId":"16931137215428552402"}}},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":75,"outputs":[]},{"cell_type":"code","metadata":{"id":"GzgfyswkE59g","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599668545491,"user_tz":180,"elapsed":1856,"user":{"displayName":"Kevin Vergara Valenzuela","photoUrl":"","userId":"16931137215428552402"}}},"source":["documents_file = drive.CreateFile({'id':documents_id})\n","documents_file.GetContentFile(documents_name)\n","documents_id_df = pd.read_csv(documents_name)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"oosDITcyP0Nn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599683790441,"user_tz":180,"elapsed":19103,"user":{"displayName":"Kevin Vergara Valenzuela","photoUrl":"","userId":"16931137215428552402"}}},"source":["dataset_name = 'DBP'\n","encoding = 'all digitalizations'\n","ids, filenames = get_datasets(dataset_name,encoding,documents_id_df)\n","dfs = read_dataframes(filenames)"],"execution_count":130,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kae-A_9trP4M","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599680349987,"user_tz":180,"elapsed":701,"user":{"displayName":"Kevin Vergara Valenzuela","photoUrl":"","userId":"16931137215428552402"}}},"source":["problemtype = 'binary_class'\n","modeltype = 'CNN'\n","#stopmetric = 'val_r_square'\n","#metrics = [r_square]\n","stopmetric = 'val_accuracy'\n","metrics=['accuracy']#, f1_m, precision_m, recall_m, matthews_correlation]\n","d = 1e-3"],"execution_count":80,"outputs":[]},{"cell_type":"code","metadata":{"id":"btK5VXHrExJ1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599683919269,"user_tz":180,"elapsed":34746,"user":{"displayName":"Kevin Vergara Valenzuela","photoUrl":"","userId":"16931137215428552402"}},"outputId":"0edc2f82-2b2e-43b0-e59a-ddd5e819b47b"},"source":["A = fftpredict(dfs[1], modeltype, problemtype, kfold_CV=False, dropout=0.2, lr=5e-4, loss_class='sparse_categorical_crossentropy',\n","                                                         loss_reg='mse', stopmetric=stopmetric, patience=200, epochs=700, batch_size=32,\n","                                                         optimizer=Adam, metrics=metrics, min_delta=d)\n","print('accruacy:')\n"],"execution_count":132,"outputs":[{"output_type":"stream","text":["Epoch 1/700\n","26/26 [==============================] - 0s 15ms/step - loss: 9.8117 - accuracy: 0.5006 - val_loss: 0.8705 - val_accuracy: 0.4466\n","Epoch 2/700\n","26/26 [==============================] - 0s 4ms/step - loss: 7.8494 - accuracy: 0.5018 - val_loss: 1.1185 - val_accuracy: 0.4466\n","Epoch 3/700\n","26/26 [==============================] - 0s 4ms/step - loss: 7.4529 - accuracy: 0.5018 - val_loss: 1.0813 - val_accuracy: 0.4466\n","Epoch 4/700\n","26/26 [==============================] - 0s 4ms/step - loss: 7.1512 - accuracy: 0.5018 - val_loss: 1.0320 - val_accuracy: 0.4466\n","Epoch 5/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.8212 - accuracy: 0.5018 - val_loss: 1.0189 - val_accuracy: 0.4466\n","Epoch 6/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.5247 - accuracy: 0.5018 - val_loss: 1.0077 - val_accuracy: 0.4466\n","Epoch 7/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.4487 - accuracy: 0.5018 - val_loss: 1.0271 - val_accuracy: 0.4466\n","Epoch 8/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.4334 - accuracy: 0.5018 - val_loss: 0.9577 - val_accuracy: 0.4466\n","Epoch 9/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.3639 - accuracy: 0.5018 - val_loss: 0.8902 - val_accuracy: 0.4466\n","Epoch 10/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.2808 - accuracy: 0.5030 - val_loss: 1.0554 - val_accuracy: 0.4466\n","Epoch 11/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.3748 - accuracy: 0.5018 - val_loss: 0.9807 - val_accuracy: 0.4466\n","Epoch 12/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.3808 - accuracy: 0.5018 - val_loss: 0.8843 - val_accuracy: 0.4466\n","Epoch 13/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.3299 - accuracy: 0.5018 - val_loss: 1.0085 - val_accuracy: 0.4466\n","Epoch 14/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.3045 - accuracy: 0.5018 - val_loss: 0.9536 - val_accuracy: 0.4466\n","Epoch 15/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.2493 - accuracy: 0.5018 - val_loss: 1.0050 - val_accuracy: 0.4466\n","Epoch 16/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.2379 - accuracy: 0.5018 - val_loss: 0.8695 - val_accuracy: 0.4466\n","Epoch 17/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.2760 - accuracy: 0.5018 - val_loss: 0.9914 - val_accuracy: 0.4466\n","Epoch 18/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.2160 - accuracy: 0.5018 - val_loss: 0.9811 - val_accuracy: 0.4466\n","Epoch 19/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.2085 - accuracy: 0.5018 - val_loss: 0.9174 - val_accuracy: 0.4466\n","Epoch 20/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.2518 - accuracy: 0.5018 - val_loss: 0.8795 - val_accuracy: 0.4466\n","Epoch 21/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.1102 - accuracy: 0.5018 - val_loss: 0.9764 - val_accuracy: 0.4466\n","Epoch 22/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.1671 - accuracy: 0.5018 - val_loss: 0.9169 - val_accuracy: 0.4466\n","Epoch 23/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.0426 - accuracy: 0.5018 - val_loss: 0.9547 - val_accuracy: 0.4466\n","Epoch 24/700\n","26/26 [==============================] - 0s 4ms/step - loss: 6.0627 - accuracy: 0.5018 - val_loss: 0.9846 - val_accuracy: 0.4466\n","Epoch 25/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.8998 - accuracy: 0.5067 - val_loss: 1.0418 - val_accuracy: 0.4466\n","Epoch 26/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.9262 - accuracy: 0.5164 - val_loss: 1.0406 - val_accuracy: 0.4466\n","Epoch 27/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.8964 - accuracy: 0.5347 - val_loss: 0.8652 - val_accuracy: 0.4854\n","Epoch 28/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.8254 - accuracy: 0.5542 - val_loss: 0.7933 - val_accuracy: 0.5583\n","Epoch 29/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.8473 - accuracy: 0.5639 - val_loss: 1.0906 - val_accuracy: 0.4466\n","Epoch 30/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.8301 - accuracy: 0.5579 - val_loss: 0.7441 - val_accuracy: 0.5874\n","Epoch 31/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.8670 - accuracy: 0.5883 - val_loss: 0.8828 - val_accuracy: 0.4903\n","Epoch 32/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.7734 - accuracy: 0.5761 - val_loss: 1.0196 - val_accuracy: 0.4660\n","Epoch 33/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.6393 - accuracy: 0.5895 - val_loss: 0.9076 - val_accuracy: 0.4951\n","Epoch 34/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.4978 - accuracy: 0.6127 - val_loss: 0.9000 - val_accuracy: 0.5340\n","Epoch 35/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.4933 - accuracy: 0.6346 - val_loss: 0.9041 - val_accuracy: 0.4951\n","Epoch 36/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.5030 - accuracy: 0.6322 - val_loss: 1.0041 - val_accuracy: 0.4903\n","Epoch 37/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.3689 - accuracy: 0.6212 - val_loss: 0.7987 - val_accuracy: 0.5825\n","Epoch 38/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.2075 - accuracy: 0.6346 - val_loss: 0.7510 - val_accuracy: 0.6311\n","Epoch 39/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.1781 - accuracy: 0.6504 - val_loss: 0.8580 - val_accuracy: 0.5777\n","Epoch 40/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.2101 - accuracy: 0.6748 - val_loss: 1.0419 - val_accuracy: 0.4903\n","Epoch 41/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.9597 - accuracy: 0.6663 - val_loss: 0.8000 - val_accuracy: 0.6117\n","Epoch 42/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.9687 - accuracy: 0.6821 - val_loss: 0.7903 - val_accuracy: 0.6214\n","Epoch 43/700\n","26/26 [==============================] - 0s 4ms/step - loss: 5.1172 - accuracy: 0.6626 - val_loss: 0.7786 - val_accuracy: 0.6262\n","Epoch 44/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.9401 - accuracy: 0.6882 - val_loss: 0.7851 - val_accuracy: 0.6408\n","Epoch 45/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.7313 - accuracy: 0.7065 - val_loss: 0.9894 - val_accuracy: 0.5485\n","Epoch 46/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.8859 - accuracy: 0.6967 - val_loss: 1.0169 - val_accuracy: 0.5243\n","Epoch 47/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.9753 - accuracy: 0.6857 - val_loss: 0.7323 - val_accuracy: 0.6456\n","Epoch 48/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.5745 - accuracy: 0.7089 - val_loss: 0.9358 - val_accuracy: 0.5728\n","Epoch 49/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.6302 - accuracy: 0.7150 - val_loss: 1.1044 - val_accuracy: 0.5097\n","Epoch 50/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.6291 - accuracy: 0.7028 - val_loss: 0.8596 - val_accuracy: 0.6165\n","Epoch 51/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.7782 - accuracy: 0.7272 - val_loss: 1.0356 - val_accuracy: 0.5485\n","Epoch 52/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.6513 - accuracy: 0.7077 - val_loss: 0.9299 - val_accuracy: 0.5825\n","Epoch 53/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.4846 - accuracy: 0.7247 - val_loss: 0.9705 - val_accuracy: 0.5825\n","Epoch 54/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.5038 - accuracy: 0.7296 - val_loss: 0.7595 - val_accuracy: 0.6602\n","Epoch 55/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.2917 - accuracy: 0.7442 - val_loss: 0.9939 - val_accuracy: 0.5777\n","Epoch 56/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.4209 - accuracy: 0.7320 - val_loss: 0.9146 - val_accuracy: 0.6311\n","Epoch 57/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.3532 - accuracy: 0.7284 - val_loss: 0.7365 - val_accuracy: 0.6650\n","Epoch 58/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.2180 - accuracy: 0.7479 - val_loss: 0.8736 - val_accuracy: 0.6311\n","Epoch 59/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.2566 - accuracy: 0.7527 - val_loss: 0.8823 - val_accuracy: 0.6311\n","Epoch 60/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.3391 - accuracy: 0.7369 - val_loss: 0.8468 - val_accuracy: 0.6359\n","Epoch 61/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.5341 - accuracy: 0.7272 - val_loss: 0.9808 - val_accuracy: 0.5874\n","Epoch 62/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.3952 - accuracy: 0.7430 - val_loss: 0.7983 - val_accuracy: 0.6408\n","Epoch 63/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.9720 - accuracy: 0.7674 - val_loss: 0.8294 - val_accuracy: 0.6650\n","Epoch 64/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.1893 - accuracy: 0.7722 - val_loss: 0.9501 - val_accuracy: 0.6068\n","Epoch 65/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.2162 - accuracy: 0.7515 - val_loss: 1.0413 - val_accuracy: 0.5728\n","Epoch 66/700\n","26/26 [==============================] - 0s 4ms/step - loss: 4.0962 - accuracy: 0.7649 - val_loss: 0.8877 - val_accuracy: 0.6408\n","Epoch 67/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.8837 - accuracy: 0.7783 - val_loss: 0.8818 - val_accuracy: 0.6359\n","Epoch 68/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.7570 - accuracy: 0.7856 - val_loss: 0.9504 - val_accuracy: 0.6408\n","Epoch 69/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.7438 - accuracy: 0.7881 - val_loss: 0.8403 - val_accuracy: 0.6456\n","Epoch 70/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.8384 - accuracy: 0.7893 - val_loss: 0.8371 - val_accuracy: 0.6650\n","Epoch 71/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.6721 - accuracy: 0.7954 - val_loss: 0.8812 - val_accuracy: 0.6456\n","Epoch 72/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.8720 - accuracy: 0.7832 - val_loss: 0.8860 - val_accuracy: 0.6456\n","Epoch 73/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.9259 - accuracy: 0.7747 - val_loss: 0.8099 - val_accuracy: 0.6893\n","Epoch 74/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.7824 - accuracy: 0.7771 - val_loss: 0.8196 - val_accuracy: 0.6748\n","Epoch 75/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.6003 - accuracy: 0.7905 - val_loss: 0.8506 - val_accuracy: 0.6796\n","Epoch 76/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.5057 - accuracy: 0.7954 - val_loss: 0.8108 - val_accuracy: 0.6942\n","Epoch 77/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.5501 - accuracy: 0.8136 - val_loss: 0.8526 - val_accuracy: 0.6602\n","Epoch 78/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.3978 - accuracy: 0.8076 - val_loss: 0.8037 - val_accuracy: 0.6796\n","Epoch 79/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.4649 - accuracy: 0.8051 - val_loss: 0.8177 - val_accuracy: 0.6845\n","Epoch 80/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.5423 - accuracy: 0.7929 - val_loss: 0.7813 - val_accuracy: 0.6796\n","Epoch 81/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.5566 - accuracy: 0.7978 - val_loss: 0.8759 - val_accuracy: 0.6602\n","Epoch 82/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.2542 - accuracy: 0.8270 - val_loss: 0.8432 - val_accuracy: 0.6893\n","Epoch 83/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.2435 - accuracy: 0.8295 - val_loss: 0.9047 - val_accuracy: 0.6650\n","Epoch 84/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.4439 - accuracy: 0.8063 - val_loss: 0.7905 - val_accuracy: 0.6893\n","Epoch 85/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.2982 - accuracy: 0.8185 - val_loss: 0.8700 - val_accuracy: 0.6796\n","Epoch 86/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.0932 - accuracy: 0.8380 - val_loss: 0.8663 - val_accuracy: 0.6699\n","Epoch 87/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.1090 - accuracy: 0.8343 - val_loss: 0.8685 - val_accuracy: 0.6699\n","Epoch 88/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.1513 - accuracy: 0.8088 - val_loss: 0.8719 - val_accuracy: 0.6796\n","Epoch 89/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.0428 - accuracy: 0.8331 - val_loss: 0.9298 - val_accuracy: 0.6553\n","Epoch 90/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.9770 - accuracy: 0.8477 - val_loss: 1.0504 - val_accuracy: 0.6553\n","Epoch 91/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.2782 - accuracy: 0.8197 - val_loss: 1.1193 - val_accuracy: 0.6262\n","Epoch 92/700\n","26/26 [==============================] - 0s 4ms/step - loss: 3.0703 - accuracy: 0.8380 - val_loss: 0.9586 - val_accuracy: 0.6602\n","Epoch 93/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.8236 - accuracy: 0.8490 - val_loss: 1.0309 - val_accuracy: 0.6505\n","Epoch 94/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.8341 - accuracy: 0.8502 - val_loss: 1.0189 - val_accuracy: 0.6553\n","Epoch 95/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.6663 - accuracy: 0.8636 - val_loss: 0.9183 - val_accuracy: 0.7087\n","Epoch 96/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.9207 - accuracy: 0.8514 - val_loss: 0.9506 - val_accuracy: 0.6602\n","Epoch 97/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.7987 - accuracy: 0.8453 - val_loss: 0.9323 - val_accuracy: 0.6845\n","Epoch 98/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.7184 - accuracy: 0.8551 - val_loss: 0.9321 - val_accuracy: 0.6893\n","Epoch 99/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.5390 - accuracy: 0.8733 - val_loss: 0.9778 - val_accuracy: 0.6990\n","Epoch 100/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.5329 - accuracy: 0.8758 - val_loss: 1.0430 - val_accuracy: 0.6553\n","Epoch 101/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.5879 - accuracy: 0.8721 - val_loss: 1.0579 - val_accuracy: 0.6553\n","Epoch 102/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.4538 - accuracy: 0.8709 - val_loss: 1.0457 - val_accuracy: 0.6602\n","Epoch 103/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.7795 - accuracy: 0.8465 - val_loss: 0.9702 - val_accuracy: 0.6845\n","Epoch 104/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.5735 - accuracy: 0.8636 - val_loss: 0.9665 - val_accuracy: 0.7136\n","Epoch 105/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.3938 - accuracy: 0.8733 - val_loss: 1.0613 - val_accuracy: 0.6699\n","Epoch 106/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.3547 - accuracy: 0.8843 - val_loss: 1.0079 - val_accuracy: 0.6893\n","Epoch 107/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.3813 - accuracy: 0.8794 - val_loss: 1.0304 - val_accuracy: 0.6845\n","Epoch 108/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.4587 - accuracy: 0.8782 - val_loss: 1.0439 - val_accuracy: 0.6748\n","Epoch 109/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.3124 - accuracy: 0.8855 - val_loss: 1.1092 - val_accuracy: 0.6602\n","Epoch 110/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.2549 - accuracy: 0.8867 - val_loss: 1.0865 - val_accuracy: 0.6990\n","Epoch 111/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.1251 - accuracy: 0.8977 - val_loss: 1.1620 - val_accuracy: 0.6505\n","Epoch 112/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.2802 - accuracy: 0.8745 - val_loss: 1.1778 - val_accuracy: 0.6650\n","Epoch 113/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.2152 - accuracy: 0.8904 - val_loss: 1.3895 - val_accuracy: 0.6408\n","Epoch 114/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.8186 - accuracy: 0.8502 - val_loss: 1.1304 - val_accuracy: 0.6796\n","Epoch 115/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.3643 - accuracy: 0.8867 - val_loss: 1.1514 - val_accuracy: 0.6553\n","Epoch 116/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.0790 - accuracy: 0.9001 - val_loss: 1.1203 - val_accuracy: 0.6942\n","Epoch 117/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.1796 - accuracy: 0.8867 - val_loss: 1.1094 - val_accuracy: 0.7039\n","Epoch 118/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.3336 - accuracy: 0.8758 - val_loss: 1.0890 - val_accuracy: 0.7136\n","Epoch 119/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.1873 - accuracy: 0.8806 - val_loss: 1.0944 - val_accuracy: 0.6893\n","Epoch 120/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.0089 - accuracy: 0.8989 - val_loss: 1.1394 - val_accuracy: 0.6845\n","Epoch 121/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.2846 - accuracy: 0.8831 - val_loss: 1.0822 - val_accuracy: 0.6893\n","Epoch 122/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.2103 - accuracy: 0.8916 - val_loss: 1.1988 - val_accuracy: 0.6748\n","Epoch 123/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.2819 - accuracy: 0.8867 - val_loss: 1.1605 - val_accuracy: 0.6893\n","Epoch 124/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.9701 - accuracy: 0.9050 - val_loss: 1.2347 - val_accuracy: 0.6602\n","Epoch 125/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.8470 - accuracy: 0.9074 - val_loss: 1.2393 - val_accuracy: 0.6748\n","Epoch 126/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.8641 - accuracy: 0.9135 - val_loss: 1.2744 - val_accuracy: 0.6602\n","Epoch 127/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.9620 - accuracy: 0.9013 - val_loss: 1.2104 - val_accuracy: 0.6942\n","Epoch 128/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.8327 - accuracy: 0.9135 - val_loss: 1.3031 - val_accuracy: 0.6845\n","Epoch 129/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.9335 - accuracy: 0.9062 - val_loss: 1.4383 - val_accuracy: 0.6408\n","Epoch 130/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.5094 - accuracy: 0.8648 - val_loss: 1.2293 - val_accuracy: 0.6699\n","Epoch 131/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.9413 - accuracy: 0.9062 - val_loss: 1.2399 - val_accuracy: 0.6845\n","Epoch 132/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.8095 - accuracy: 0.9086 - val_loss: 1.2748 - val_accuracy: 0.6748\n","Epoch 133/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.8227 - accuracy: 0.9135 - val_loss: 1.2444 - val_accuracy: 0.7087\n","Epoch 134/700\n","26/26 [==============================] - 0s 4ms/step - loss: 2.3546 - accuracy: 0.8758 - val_loss: 1.1785 - val_accuracy: 0.7087\n","Epoch 135/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.9757 - accuracy: 0.9013 - val_loss: 1.2685 - val_accuracy: 0.6942\n","Epoch 136/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.9564 - accuracy: 0.9074 - val_loss: 1.2654 - val_accuracy: 0.6650\n","Epoch 137/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.8164 - accuracy: 0.9135 - val_loss: 1.2177 - val_accuracy: 0.6942\n","Epoch 138/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.8892 - accuracy: 0.9123 - val_loss: 1.2464 - val_accuracy: 0.6796\n","Epoch 139/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.6855 - accuracy: 0.9196 - val_loss: 1.2508 - val_accuracy: 0.6845\n","Epoch 140/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.6492 - accuracy: 0.9172 - val_loss: 1.2770 - val_accuracy: 0.6845\n","Epoch 141/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.5460 - accuracy: 0.9306 - val_loss: 1.3504 - val_accuracy: 0.6845\n","Epoch 142/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.5369 - accuracy: 0.9245 - val_loss: 1.2987 - val_accuracy: 0.6845\n","Epoch 143/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.7023 - accuracy: 0.9172 - val_loss: 1.2957 - val_accuracy: 0.6796\n","Epoch 144/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.6714 - accuracy: 0.9233 - val_loss: 1.3972 - val_accuracy: 0.6650\n","Epoch 145/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.5387 - accuracy: 0.9294 - val_loss: 1.4179 - val_accuracy: 0.6699\n","Epoch 146/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.4250 - accuracy: 0.9367 - val_loss: 1.4147 - val_accuracy: 0.6699\n","Epoch 147/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.3769 - accuracy: 0.9379 - val_loss: 1.4056 - val_accuracy: 0.6796\n","Epoch 148/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.5524 - accuracy: 0.9233 - val_loss: 1.4266 - val_accuracy: 0.6942\n","Epoch 149/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.4525 - accuracy: 0.9281 - val_loss: 1.4079 - val_accuracy: 0.6990\n","Epoch 150/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.6250 - accuracy: 0.9184 - val_loss: 1.3978 - val_accuracy: 0.6748\n","Epoch 151/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.4835 - accuracy: 0.9318 - val_loss: 1.4179 - val_accuracy: 0.6748\n","Epoch 152/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.5597 - accuracy: 0.9208 - val_loss: 1.3753 - val_accuracy: 0.6845\n","Epoch 153/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.6075 - accuracy: 0.9196 - val_loss: 1.4529 - val_accuracy: 0.6650\n","Epoch 154/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.6200 - accuracy: 0.9233 - val_loss: 1.5473 - val_accuracy: 0.6602\n","Epoch 155/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.6555 - accuracy: 0.9160 - val_loss: 1.4090 - val_accuracy: 0.6796\n","Epoch 156/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.4782 - accuracy: 0.9269 - val_loss: 1.5038 - val_accuracy: 0.6748\n","Epoch 157/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.3777 - accuracy: 0.9367 - val_loss: 1.5441 - val_accuracy: 0.7087\n","Epoch 158/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.4030 - accuracy: 0.9318 - val_loss: 1.4877 - val_accuracy: 0.6796\n","Epoch 159/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.3568 - accuracy: 0.9415 - val_loss: 1.5160 - val_accuracy: 0.6893\n","Epoch 160/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.3536 - accuracy: 0.9330 - val_loss: 1.6159 - val_accuracy: 0.6748\n","Epoch 161/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.2357 - accuracy: 0.9415 - val_loss: 1.5619 - val_accuracy: 0.6845\n","Epoch 162/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.2662 - accuracy: 0.9391 - val_loss: 1.5583 - val_accuracy: 0.6893\n","Epoch 163/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.3230 - accuracy: 0.9318 - val_loss: 1.5496 - val_accuracy: 0.6845\n","Epoch 164/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.3528 - accuracy: 0.9391 - val_loss: 1.6688 - val_accuracy: 0.6650\n","Epoch 165/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.5763 - accuracy: 0.9233 - val_loss: 1.5051 - val_accuracy: 0.6602\n","Epoch 166/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.6057 - accuracy: 0.9220 - val_loss: 1.6382 - val_accuracy: 0.6359\n","Epoch 167/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.5227 - accuracy: 0.9294 - val_loss: 1.5894 - val_accuracy: 0.6748\n","Epoch 168/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.5586 - accuracy: 0.9160 - val_loss: 1.4912 - val_accuracy: 0.6942\n","Epoch 169/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.3896 - accuracy: 0.9233 - val_loss: 1.5162 - val_accuracy: 0.6893\n","Epoch 170/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.3852 - accuracy: 0.9281 - val_loss: 1.5100 - val_accuracy: 0.6748\n","Epoch 171/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.3525 - accuracy: 0.9379 - val_loss: 1.5059 - val_accuracy: 0.6602\n","Epoch 172/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.3753 - accuracy: 0.9379 - val_loss: 1.5818 - val_accuracy: 0.6990\n","Epoch 173/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.2923 - accuracy: 0.9452 - val_loss: 1.6600 - val_accuracy: 0.6990\n","Epoch 174/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.2108 - accuracy: 0.9440 - val_loss: 1.6198 - val_accuracy: 0.6650\n","Epoch 175/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.1613 - accuracy: 0.9464 - val_loss: 1.6985 - val_accuracy: 0.6942\n","Epoch 176/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.1899 - accuracy: 0.9452 - val_loss: 1.6221 - val_accuracy: 0.6845\n","Epoch 177/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.0572 - accuracy: 0.9464 - val_loss: 1.7655 - val_accuracy: 0.6650\n","Epoch 178/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.2118 - accuracy: 0.9452 - val_loss: 1.6158 - val_accuracy: 0.6650\n","Epoch 179/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.2030 - accuracy: 0.9428 - val_loss: 1.6052 - val_accuracy: 0.6845\n","Epoch 180/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.1461 - accuracy: 0.9415 - val_loss: 1.7353 - val_accuracy: 0.6650\n","Epoch 181/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.5613 - accuracy: 0.9269 - val_loss: 1.7026 - val_accuracy: 0.6893\n","Epoch 182/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.1819 - accuracy: 0.9391 - val_loss: 1.6126 - val_accuracy: 0.6893\n","Epoch 183/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.8197 - accuracy: 0.9086 - val_loss: 1.8951 - val_accuracy: 0.6262\n","Epoch 184/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.6253 - accuracy: 0.9135 - val_loss: 1.5224 - val_accuracy: 0.6845\n","Epoch 185/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.2528 - accuracy: 0.9342 - val_loss: 1.6286 - val_accuracy: 0.6942\n","Epoch 186/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.3495 - accuracy: 0.9306 - val_loss: 1.4995 - val_accuracy: 0.6748\n","Epoch 187/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.3256 - accuracy: 0.9391 - val_loss: 1.6389 - val_accuracy: 0.6650\n","Epoch 188/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.1119 - accuracy: 0.9501 - val_loss: 1.9268 - val_accuracy: 0.6456\n","Epoch 189/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.1481 - accuracy: 0.9428 - val_loss: 1.7703 - val_accuracy: 0.6748\n","Epoch 190/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.1728 - accuracy: 0.9440 - val_loss: 1.6198 - val_accuracy: 0.6893\n","Epoch 191/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.0511 - accuracy: 0.9513 - val_loss: 1.8282 - val_accuracy: 0.6748\n","Epoch 192/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.1654 - accuracy: 0.9354 - val_loss: 1.8133 - val_accuracy: 0.6796\n","Epoch 193/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.1193 - accuracy: 0.9452 - val_loss: 1.7381 - val_accuracy: 0.6796\n","Epoch 194/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.0455 - accuracy: 0.9513 - val_loss: 1.7848 - val_accuracy: 0.6699\n","Epoch 195/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.3822 - accuracy: 0.9281 - val_loss: 1.6568 - val_accuracy: 0.6699\n","Epoch 196/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.0998 - accuracy: 0.9415 - val_loss: 1.8060 - val_accuracy: 0.6650\n","Epoch 197/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.9690 - accuracy: 0.9574 - val_loss: 1.7703 - val_accuracy: 0.6602\n","Epoch 198/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.9918 - accuracy: 0.9549 - val_loss: 1.7570 - val_accuracy: 0.6893\n","Epoch 199/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.9134 - accuracy: 0.9549 - val_loss: 1.8590 - val_accuracy: 0.6699\n","Epoch 200/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.0071 - accuracy: 0.9501 - val_loss: 1.8410 - val_accuracy: 0.6748\n","Epoch 201/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.0062 - accuracy: 0.9428 - val_loss: 1.7604 - val_accuracy: 0.6796\n","Epoch 202/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.2275 - accuracy: 0.9415 - val_loss: 1.7255 - val_accuracy: 0.6845\n","Epoch 203/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.0831 - accuracy: 0.9476 - val_loss: 1.9669 - val_accuracy: 0.6505\n","Epoch 204/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8952 - accuracy: 0.9562 - val_loss: 1.9148 - val_accuracy: 0.6699\n","Epoch 205/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8221 - accuracy: 0.9610 - val_loss: 1.7925 - val_accuracy: 0.6990\n","Epoch 206/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.9481 - accuracy: 0.9513 - val_loss: 1.9036 - val_accuracy: 0.6942\n","Epoch 207/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.2184 - accuracy: 0.9440 - val_loss: 1.9759 - val_accuracy: 0.6650\n","Epoch 208/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.0753 - accuracy: 0.9452 - val_loss: 1.6628 - val_accuracy: 0.6942\n","Epoch 209/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8314 - accuracy: 0.9537 - val_loss: 1.8027 - val_accuracy: 0.6942\n","Epoch 210/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8489 - accuracy: 0.9574 - val_loss: 1.8119 - val_accuracy: 0.6796\n","Epoch 211/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.6654 - accuracy: 0.9671 - val_loss: 1.9737 - val_accuracy: 0.6796\n","Epoch 212/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7906 - accuracy: 0.9598 - val_loss: 1.9013 - val_accuracy: 0.6748\n","Epoch 213/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7319 - accuracy: 0.9635 - val_loss: 1.9782 - val_accuracy: 0.6650\n","Epoch 214/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.9659 - val_loss: 1.9906 - val_accuracy: 0.6796\n","Epoch 215/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7176 - accuracy: 0.9598 - val_loss: 2.0988 - val_accuracy: 0.6796\n","Epoch 216/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7013 - accuracy: 0.9622 - val_loss: 2.0574 - val_accuracy: 0.6602\n","Epoch 217/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8855 - accuracy: 0.9525 - val_loss: 2.1086 - val_accuracy: 0.6748\n","Epoch 218/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8168 - accuracy: 0.9635 - val_loss: 2.0448 - val_accuracy: 0.6553\n","Epoch 219/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.1200 - accuracy: 0.9318 - val_loss: 1.9908 - val_accuracy: 0.6845\n","Epoch 220/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.9198 - accuracy: 0.9501 - val_loss: 2.0454 - val_accuracy: 0.6505\n","Epoch 221/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7783 - accuracy: 0.9586 - val_loss: 1.7713 - val_accuracy: 0.6748\n","Epoch 222/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.6980 - accuracy: 0.9659 - val_loss: 2.1682 - val_accuracy: 0.6602\n","Epoch 223/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.5848 - accuracy: 0.9683 - val_loss: 1.9731 - val_accuracy: 0.6699\n","Epoch 224/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.9708 - val_loss: 2.2134 - val_accuracy: 0.6796\n","Epoch 225/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.9683 - val_loss: 1.9860 - val_accuracy: 0.6602\n","Epoch 226/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8928 - accuracy: 0.9574 - val_loss: 1.9434 - val_accuracy: 0.6845\n","Epoch 227/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.0453 - accuracy: 0.9403 - val_loss: 2.0430 - val_accuracy: 0.7087\n","Epoch 228/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8470 - accuracy: 0.9501 - val_loss: 1.8808 - val_accuracy: 0.6650\n","Epoch 229/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7722 - accuracy: 0.9574 - val_loss: 1.9740 - val_accuracy: 0.6845\n","Epoch 230/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.9671 - val_loss: 2.1535 - val_accuracy: 0.6699\n","Epoch 231/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7751 - accuracy: 0.9622 - val_loss: 2.3065 - val_accuracy: 0.6408\n","Epoch 232/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.9695 - val_loss: 2.1929 - val_accuracy: 0.6699\n","Epoch 233/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.9744 - val_loss: 2.1621 - val_accuracy: 0.6893\n","Epoch 234/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.9781 - val_loss: 2.3450 - val_accuracy: 0.6796\n","Epoch 235/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.9720 - val_loss: 2.3098 - val_accuracy: 0.6699\n","Epoch 236/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.9708 - val_loss: 2.2434 - val_accuracy: 0.6650\n","Epoch 237/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7659 - accuracy: 0.9635 - val_loss: 2.0964 - val_accuracy: 0.6650\n","Epoch 238/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.9708 - val_loss: 2.3534 - val_accuracy: 0.6699\n","Epoch 239/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8085 - accuracy: 0.9635 - val_loss: 2.0471 - val_accuracy: 0.6942\n","Epoch 240/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.5962 - accuracy: 0.9756 - val_loss: 2.5092 - val_accuracy: 0.6505\n","Epoch 241/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.3095 - accuracy: 0.9403 - val_loss: 1.6710 - val_accuracy: 0.6845\n","Epoch 242/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7747 - accuracy: 0.9622 - val_loss: 2.1827 - val_accuracy: 0.6845\n","Epoch 243/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8619 - accuracy: 0.9574 - val_loss: 2.0674 - val_accuracy: 0.6505\n","Epoch 244/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.9720 - val_loss: 2.1945 - val_accuracy: 0.6553\n","Epoch 245/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.9671 - val_loss: 1.9593 - val_accuracy: 0.6845\n","Epoch 246/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8598 - accuracy: 0.9549 - val_loss: 2.0813 - val_accuracy: 0.6650\n","Epoch 247/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7159 - accuracy: 0.9598 - val_loss: 1.8962 - val_accuracy: 0.6748\n","Epoch 248/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7061 - accuracy: 0.9671 - val_loss: 2.1797 - val_accuracy: 0.6553\n","Epoch 249/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.6973 - accuracy: 0.9671 - val_loss: 1.9125 - val_accuracy: 0.6845\n","Epoch 250/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.9769 - val_loss: 2.2373 - val_accuracy: 0.6796\n","Epoch 251/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.9829 - val_loss: 2.2090 - val_accuracy: 0.6748\n","Epoch 252/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.0094 - accuracy: 0.9464 - val_loss: 2.0501 - val_accuracy: 0.6602\n","Epoch 253/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.0239 - accuracy: 0.9428 - val_loss: 2.1990 - val_accuracy: 0.6845\n","Epoch 254/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.4757 - accuracy: 0.9233 - val_loss: 2.1089 - val_accuracy: 0.7039\n","Epoch 255/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7906 - accuracy: 0.9501 - val_loss: 2.1527 - val_accuracy: 0.6456\n","Epoch 256/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.9732 - val_loss: 2.1585 - val_accuracy: 0.6650\n","Epoch 257/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7288 - accuracy: 0.9586 - val_loss: 1.9766 - val_accuracy: 0.6748\n","Epoch 258/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.9671 - val_loss: 2.3369 - val_accuracy: 0.6408\n","Epoch 259/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.9695 - val_loss: 2.5405 - val_accuracy: 0.6553\n","Epoch 260/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7303 - accuracy: 0.9586 - val_loss: 2.0040 - val_accuracy: 0.6845\n","Epoch 261/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.9647 - val_loss: 2.0791 - val_accuracy: 0.6650\n","Epoch 262/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.9805 - val_loss: 2.3081 - val_accuracy: 0.6553\n","Epoch 263/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7830 - accuracy: 0.9562 - val_loss: 1.9440 - val_accuracy: 0.6845\n","Epoch 264/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.9659 - val_loss: 2.1270 - val_accuracy: 0.6699\n","Epoch 265/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.9769 - val_loss: 2.1496 - val_accuracy: 0.6650\n","Epoch 266/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7418 - accuracy: 0.9598 - val_loss: 2.0885 - val_accuracy: 0.6602\n","Epoch 267/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.9756 - val_loss: 2.3533 - val_accuracy: 0.6602\n","Epoch 268/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.3820 - accuracy: 0.9805 - val_loss: 2.2296 - val_accuracy: 0.6699\n","Epoch 269/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.3869 - accuracy: 0.9866 - val_loss: 2.3562 - val_accuracy: 0.6602\n","Epoch 270/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.9744 - val_loss: 2.2459 - val_accuracy: 0.6893\n","Epoch 271/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.3660 - accuracy: 0.9829 - val_loss: 2.3518 - val_accuracy: 0.6650\n","Epoch 272/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.9842 - val_loss: 2.3597 - val_accuracy: 0.6699\n","Epoch 273/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.2747 - accuracy: 0.9903 - val_loss: 2.4578 - val_accuracy: 0.6650\n","Epoch 274/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.3393 - accuracy: 0.9842 - val_loss: 2.4031 - val_accuracy: 0.6650\n","Epoch 275/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.9756 - val_loss: 2.3818 - val_accuracy: 0.6602\n","Epoch 276/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.6351 - accuracy: 0.9708 - val_loss: 2.3263 - val_accuracy: 0.6748\n","Epoch 277/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.9635 - val_loss: 2.2874 - val_accuracy: 0.6699\n","Epoch 278/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.9683 - val_loss: 2.0533 - val_accuracy: 0.6796\n","Epoch 279/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.9842 - val_loss: 2.1580 - val_accuracy: 0.6699\n","Epoch 280/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.9769 - val_loss: 2.4101 - val_accuracy: 0.6505\n","Epoch 281/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.9842 - val_loss: 2.2225 - val_accuracy: 0.6699\n","Epoch 282/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.9842 - val_loss: 2.4946 - val_accuracy: 0.6699\n","Epoch 283/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.9805 - val_loss: 2.4116 - val_accuracy: 0.6650\n","Epoch 284/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.3047 - accuracy: 0.9854 - val_loss: 2.3840 - val_accuracy: 0.6699\n","Epoch 285/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.9829 - val_loss: 2.3894 - val_accuracy: 0.6650\n","Epoch 286/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.9659 - val_loss: 2.3868 - val_accuracy: 0.6699\n","Epoch 287/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.6622 - accuracy: 0.9671 - val_loss: 2.2528 - val_accuracy: 0.6553\n","Epoch 288/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7571 - accuracy: 0.9659 - val_loss: 2.0998 - val_accuracy: 0.6408\n","Epoch 289/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8907 - accuracy: 0.9610 - val_loss: 2.0928 - val_accuracy: 0.6893\n","Epoch 290/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8780 - accuracy: 0.9537 - val_loss: 1.9801 - val_accuracy: 0.6845\n","Epoch 291/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.6994 - accuracy: 0.9635 - val_loss: 2.0807 - val_accuracy: 0.6990\n","Epoch 292/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.3596 - accuracy: 0.9769 - val_loss: 2.3655 - val_accuracy: 0.6602\n","Epoch 293/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.9842 - val_loss: 2.3892 - val_accuracy: 0.6748\n","Epoch 294/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.3688 - accuracy: 0.9817 - val_loss: 2.6023 - val_accuracy: 0.6553\n","Epoch 295/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.9842 - val_loss: 2.3266 - val_accuracy: 0.6650\n","Epoch 296/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.2798 - accuracy: 0.9866 - val_loss: 2.2862 - val_accuracy: 0.6699\n","Epoch 297/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.9720 - val_loss: 2.5954 - val_accuracy: 0.6699\n","Epoch 298/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.8792 - accuracy: 0.9172 - val_loss: 2.1101 - val_accuracy: 0.6505\n","Epoch 299/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.7773 - accuracy: 0.9172 - val_loss: 2.0245 - val_accuracy: 0.6505\n","Epoch 300/700\n","26/26 [==============================] - 0s 4ms/step - loss: 1.2793 - accuracy: 0.9513 - val_loss: 1.7462 - val_accuracy: 0.6359\n","Epoch 301/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8887 - accuracy: 0.9476 - val_loss: 1.9240 - val_accuracy: 0.6553\n","Epoch 302/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.7711 - accuracy: 0.9598 - val_loss: 1.6784 - val_accuracy: 0.6748\n","Epoch 303/700\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8200 - accuracy: 0.9562 - val_loss: 2.0486 - val_accuracy: 0.6262\n","Epoch 304/700\n","20/26 [======================>.......] - ETA: 0s - loss: 0.9063 - accuracy: 0.9547Restoring model weights from the end of the best epoch.\n","26/26 [==============================] - 0s 4ms/step - loss: 0.8665 - accuracy: 0.9488 - val_loss: 1.9741 - val_accuracy: 0.6748\n","Epoch 00304: early stopping\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["accruacy:\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5JiqB1WNXofk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1599675833591,"user_tz":180,"elapsed":820,"user":{"displayName":"Kevin Vergara Valenzuela","photoUrl":"","userId":"16931137215428552402"}},"outputId":"f0cb3d9e-f434-40ea-b074-be2f0aef4a1e"},"source":["#for i in [1e-2,1e-3,1,1e+1,1e+2,1e+3]:\n","for i in range(1,2):\n","  #scores_0 = rf_mod(dfs[4], problemtype, kfold_CV=False, ntree=200, n_jobs=-1, bootstrap=True,\n"," #                       max_features=14, min_samples_leaf=1, min_samples_split=2,verb=1)\n","  #scores_0 = svm_mod(dfs[6], problemtype, kfold_CV=False, C=400, kernel='rbf', gamma=1e+2, verb=1, n_jobs=-1)\n","  scores_0 = knn_mod(dfs[1], problemtype, kfold_CV=False, kmin=1, kmax=20, K=3)\n","  print(f'property {i}:')\n","  #print(max(scores_0[0]))\n","  #ind = scores_0[2].index(max(scores_0[2]))\n","  #print(scores_0[3][ind])\n","  #A = [i for i in range(1,21)]\n","  #plt.plot(A,scores_0[2],'-b')\n","  #plt.plot(A,scores_0[3],'-r')\n","  #plt.show()\n","  #print(A[ind])\n","  print(scores_0)\n","  print('-------------------------------------------------------')"],"execution_count":50,"outputs":[{"output_type":"stream","text":["[[ 83   9  30   2   1  28]\n"," [ 12   7   1   0   0   1]\n"," [ 56   0   3   1   1  10]\n"," [ 10   4   0   0   3   0]\n"," [ 13   1   0   3   0   0]\n"," [ 65   2   8   2   0 404]]\n","property 1:\n","None\n","-------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vhTearN3mYqu","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1599659109375,"user_tz":180,"elapsed":1316,"user":{"displayName":"Kevin Vergara Valenzuela","photoUrl":"","userId":"16931137215428552402"}}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","\n","!pip install -q sklearn\n","!pip install bayesian-optimization\n","!pip install PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import os\n","import sys\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import math as mt\n","import time\n","import tensorflow.keras\n","import tensorflow.keras.initializers\n","from sklearn.model_selection import train_test_split, cross_validate\n","from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n","from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n","from sklearn.svm import SVC, SVR\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.losses import sparse_categorical_crossentropy\n","from tensorflow.keras.optimizers import Adam, Adamax, Adagrad, Adadelta\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.layers import LeakyReLU,PReLU, ELU\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer, BatchNormalization, concatenate, Input, Conv1D, MaxPooling1D, Flatten, LSTM, Bidirectional, TimeDistributed, Reshape, GlobalMaxPooling1D, GlobalMaxPool1D, AvgPool1D\n","from tensorflow.keras import regularizers\n","import time\n","import warnings\n","\n","documents_id = '1Z4mHE2N8Jy7Zjd4jZ973HtPHu8-JhhlQ'\n","documents_name = 'google_drive_documents_ids.csv'\n","\n","def r_square(y_true, y_pred):\n","  from keras import backend as K\n","  SS_res = K.sum(K.square(y_pred - y_true))\n","  SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n","  R2 = 1 - SS_res/(SS_tot + K.epsilon())\n","  return R2\n","\n","from keras import backend as K\n","\n","def recall_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def precision_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def f1_m(y_true, y_pred):\n","    precision = precision_m(y_true, y_pred)\n","    recall = recall_m(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","def matthews_correlation(y_true, y_pred):\n","    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n","    y_pred_neg = 1 - y_pred_pos\n","\n","    y_pos = K.round(K.clip(y_true, 0, 1))\n","    y_neg = 1 - y_pos\n","\n","    tp = K.sum(y_pos * y_pred_pos)\n","    tn = K.sum(y_neg * y_pred_neg)\n","\n","    fp = K.sum(y_neg * y_pred_pos)\n","    fn = K.sum(y_pos * y_pred_neg)\n","\n","    numerator = (tp * tn - fp * fn)\n","    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n","\n","    return numerator / (denominator + K.epsilon())\n","\n","def get_datasets(set_name,encoding,df):\n","  ids=[]\n","  filenames=[]\n","  PCprops = ['PRAM900102','PRAM900103','COSI940101','HOPT810101','JOND750101','RADA880106','GRAR740103','FASG760101']\n","  if encoding=='onehot':\n","    ids = [df[df['Unnamed: 0']==set_name]['One_hot'].iloc[0]]\n","    filenames = ['One_hot ' + set_name + '.csv']\n","  elif encoding=='ordinal':\n","    ids = [df[df['Unnamed: 0']==set_name]['Ordinal'].iloc[0]]\n","    filenames = ['Ordinal ' + set_name + '.csv']\n","  elif encoding=='AAC':\n","    ids = [df[df['Unnamed: 0']==set_name]['AAC'].iloc[0]]\n","    filenames = ['AAC ' + set_name + '.csv']\n","  elif encoding=='dipeptide_comp':\n","    ids = [df[df['Unnamed: 0']==set_name]['dipeptide_comp'].iloc[0]]\n","    filenames = ['dipeptide_comp ' + set_name + '.csv']\n","  elif encoding=='all digitalizations':\n","    for prop in PCprops:\n","      ids += [df[df['Unnamed: 0']==set_name]['digitalization ' + prop].iloc[0]]\n","      filenames += ['digitalization ' + prop + ' ' + set_name + '.csv']\n","  elif PCprops.count(encoding)==1:\n","    ids = [df[df['Unnamed: 0']==set_name]['digitalization ' + encoding].iloc[0]]\n","    filenames = ['digitalization ' + encoding + ' ' + set_name + '.csv']\n","  for i in range(0,len(ids)):\n","    documents_file = drive.CreateFile({'id':ids[i]})\n","    documents_file.GetContentFile(filenames[i])\n","  return ids, filenames\n","\n","\n","def read_dataframes(filenames):\n","  dfs = []\n","  for filename in filenames:\n","    df = pd.read_csv(filename)\n","    dfs += [df]\n","  return dfs\n","\n","def fftpredict(dataframe, modeltype, problemtype, kfold_CV=True, dropout=0.2, lr=1e-4, loss_class='sparse_categorical_crossentropy', \n","               loss_reg='mse', stopmetric='val_loss', patience=200, epochs=1000, batch_size=32,\n","               optimizer=Adam, metrics=['accuracy'], min_delta=1e-3):\n","\n","  df = dataframe\n","  if problemtype=='regression':\n","      df = df[df['response'].notna()]\n","  df = df.sample(frac=1).reset_index(drop=True)\n","\n","  verbosity = 1\n","  columns = df.columns.tolist()\n","  samples = len(df[columns[1]])\n","\n","  if df.columns[0]=='class':\n","    no_outputs = len(df['class'].unique())\n","  elif df.columns[0]=='response':\n","    no_outputs = 1\n","\n","  if problemtype=='multiclass':\n","    LE = LabelEncoder()\n","    numerics=LE.fit(df['class'].tolist())\n","    transformed = LE.transform(df['class'].tolist())\n","    df['class'] = transformed\n","\n","  # Split training and external validation set, establish number of k-folds for internal validation\n","  if samples > 100 and samples <= 500:\n","    dtrain, deval = train_test_split(df, test_size=0.3)\n","    num_folds = 10\n","  elif samples > 500:\n","    dtrain, deval = train_test_split(df, test_size=0.2)\n","    num_folds = 5\n","  elif samples <= 100:\n","    dtrain = df\n","    deval = []\n","    num_folds = samples\n","\n","  # Determine shape of the data\n","  input_shape = (len(columns)-1, )\n","\n","  # Define per-fold score containers\n","  acc_per_fold = []\n","  loss_per_fold = []\n","\n","  # Define the K-fold Cross Validator\n","  kfold = KFold(n_splits=num_folds, shuffle=True)\n","\n","  # Seperate inputs and target values\n","  target_train = dtrain.pop(columns[0])\n","  input_train = dtrain.astype('float64')/dtrain.max().max()\n","  target_eval = deval.pop(columns[0])\n","  input_eval = deval.astype('float64')/dtrain.max().max()\n","\n","\n","  def generate_model(dropout,modeltype,problemtype):\n","    if modeltype=='ANN':\n","      inp = Input(shape=input_shape)\n","      model = Dense(256, activation='relu')(inp)\n","      model = Dropout(dropout)(model)\n","      model = Dense(128, activation='relu')(model)\n","      model = Dense(16, activation='relu')(model) \n","      model = Dropout(dropout)(model)\n","    elif modeltype=='LSTM':\n","      inp = Input(shape=(dtrain.shape[1],1))\n","      model = Bidirectional(LSTM(64, return_sequences =True, dropout=dropout))(inp)\n","      model = Dense(16, activation='relu')(model)\n","      model = Dropout(dropout)(model)\n","    elif modeltype=='CNN':\n","      inp = Input(shape=(dtrain.shape[1],1))\n","      model = Conv1D(filters=256, kernel_size=3, activation='relu')(inp)\n","      model = MaxPooling1D(pool_size=2)(model)\n","      model = Dropout(dropout)(model)\n","      model = Conv1D(filters=128, kernel_size=3, activation='relu')(model)\n","      model = MaxPooling1D(pool_size=2)(model)\n","      model = Dropout(dropout)(model)\n","      model = Flatten()(model)\n","      model = Dense(16, activation='relu')(model)\n","    if problemtype=='binary_class':\n","      model = Dense(2)(model)\n","      out = Activation('softmax')(model)\n","    elif problemtype=='multiclass':\n","      model = Dense(6)(model)\n","      out = Activation('softmax')(model)\n","    elif problemtype=='regression':\n","      out = Dense(1)(model)\n","    final = Model(inputs=[inp], outputs=[out])\n","    return final    \n","\n","  def evaluate_complete_model(modeltype, problemtype, kfold_CV, dropout, lr,\n","                              loss_class, loss_reg, stopmetric, patience, epochs, batch_size, optimizer, metrics, min_delta):\n","    batch_size = batch_size\n","    epochs_needed = []\n","    num = 0\n","    acc_per_fold = [] #acc or R2\n","    loss_per_fold = []\n","    start_time = time.time()\n","\n","    if kfold_CV==True:\n","      # K-fold Cross Validation model procedure\n","      fold_no = 1\n","      for train, internal_test in kfold.split(input_train, target_train):\n","        num+=1\n","\n","        # Model architect and hyperparameters establishment\n","        model = generate_model(dropout,modeltype,problemtype)\n","        if problemtype=='binary_class' or problemtype=='multiclass':\n","          loss=loss_class\n","        elif problemtype=='regression':\n","          loss=loss_reg\n","        if stopmetric=='val_r_square':\n","          mode = 'max'\n","        else:\n","          mode = 'auto'\n","        model.compile(loss=loss, optimizer=optimizer(lr=lr), metrics=metrics)\n","        monitor = EarlyStopping(monitor=stopmetric, min_delta=min_delta, \n","        patience=patience, verbose=0, mode=mode, restore_best_weights=True)\n","\n","        # Define training and validation subset within specific kfold set\n","        x_train = input_train.iloc[train]\n","        y_train = target_train.iloc[train]\n","        x_test = input_train.iloc[internal_test]\n","        y_test = target_train.iloc[internal_test]\n","\n","        # Generate a print\n","        print('------------------------------------------------------------------------')\n","        print(f'Training for fold {fold_no} ...')\n","\n","        # Train on the kfold sample\n","        model.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor], epochs=epochs, batch_size=batch_size, verbose=verbosity)\n","        epochs_end = monitor.stopped_epoch\n","        epochs_needed.append(epochs_end)\n","\n","        # Generate generalization metrics\n","        scores = model.evaluate(x_test, y_test, verbose=0)\n","        if problemtype=='regression':\n","          print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}')\n","          C = 1\n","        else:\n","          print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n","          C = 100\n","        acc_per_fold.append(scores[1] * C)\n","        loss_per_fold.append(scores[0])\n","\n","        # Increase fold number\n","        fold_no = fold_no + 1\n","\n","      time_took = time.time() - start_time\n","      print(f'time took for kfold_CV: {time_took}')\n","\n","      # Provide average scores      \n","      m1 = np.mean(loss_per_fold)\n","      m2 = np.mean(acc_per_fold)\n","      m3 = np.mean(epochs_needed)\n","      m1dev = np.std(loss_per_fold)\n","      m2dev = np.std(acc_per_fold)\n","      m3dev = np.std(epochs_needed)\n","      scores2 = model.evaluate(input_eval,target_eval)\n","      if problemtype=='regression':\n","        print(f'loss: {m1} +- {m1dev}, error: {m2} +- {m2dev}, epochs: {m3} +- {m3dev}, test error: {scores2[1]}')\n","      else:\n","        print(f'loss: {m1} +- {m1dev}, accuracy: {m2} +- {m2dev}, epochs: {m3} +- {m3dev}, test acc: {scores2[1]*100}')\n","      tensorflow.keras.backend.clear_session()\n","      stat = [m1,m1dev,m2,m2dev,m3,m3dev]\n","      return stat\n","\n","    elif kfold_CV==False:\n","      start_time = time.time()\n","      model = generate_model(dropout,modeltype,problemtype)\n","      if problemtype=='binary_class' or problemtype=='multiclass':\n","        loss=loss_class\n","      elif problemtype=='regression':\n","        loss=loss_reg\n","      model.compile(loss=loss, optimizer=optimizer(lr=lr), metrics=metrics)\n","      monitor = EarlyStopping(monitor=stopmetric, min_delta=min_delta, \n","                              patience=patience, verbose=1, mode='auto', restore_best_weights=True)\n","      x_train = input_train\n","      y_train = target_train\n","      x_test = input_eval\n","      y_test = target_eval\n","\n","      history = model.fit(x=x_train,y=y_train,validation_data=(x_test,y_test), callbacks=[monitor], epochs=epochs, batch_size=batch_size, verbose=verbosity)\n","\n","      time_took = time.time() - start_time\n","      print(f'time took for training on whole set: {time_took}')\n","\n","  print(evaluate_complete_model(modeltype, problemtype, kfold_CV, dropout, lr, \n","                          loss_class, loss_reg, stopmetric, patience, epochs, batch_size, optimizer, metrics, min_delta))\n","  \n","\n","def knn_mod(dataframe, problemtype, kfold_CV=True, kmin=1, kmax=20, verb=1, K=1, target_names=['clase 0','clase 1']):\n","  df = dataframe\n","  if problemtype=='regression':\n","      df = df[df['response'].notna()]\n","  df = df.sample(frac=1).reset_index(drop=True)\n","  #samples = len(df['p0'])\n","\n","  verbosity = 1\n","  columns = df.columns.tolist()\n","  samples = len(df[columns[1]])\n","\n","  if problemtype=='multiclass':\n","    LE = LabelEncoder()\n","    numerics=LE.fit(df['class'].tolist())\n","    transformed = LE.transform(df['class'].tolist())\n","    df['class'] = transformed\n","\n","  if problemtype=='binary_class' and isinstance(df['class'].iloc[0],str):\n","    LE = LabelEncoder()\n","    numerics=LE.fit(df['class'].tolist())\n","    transformed = LE.transform(df['class'].tolist())\n","    df['class'] = transformed\n","\n","  # Split training and external validation set, establish number of k-folds for internal validation\n","  if samples > 100 and samples <= 500:\n","    dtrain, deval = train_test_split(df, test_size=0.3)\n","    num_folds = 10\n","  elif samples > 500:\n","    dtrain, deval = train_test_split(df, test_size=0.2)\n","    num_folds = 5\n","  elif samples <= 100:\n","    dtrain = df\n","    deval = []\n","    num_folds = samples\n","\n","  # Determine shape of the data\n","  input_shape = (len(columns)-1, )\n","\n","  # Define per-fold score containers\n","  acc_per_fold = []\n","  loss_per_fold = []\n","\n","  # Define the K-fold Cross Validator\n","  kfold = KFold(n_splits=num_folds, shuffle=True)\n","\n","  # Seperate inputs and target values\n","  target_train = dtrain.pop(columns[0])\n","  input_train = dtrain.astype('float64')/dtrain.max().max()\n","  target_test = deval.pop(columns[0])\n","  input_test = deval.astype('float64')/dtrain.max().max()\n","\n","  if kfold_CV==True:\n","    k_range = range(kmin, kmax+1)\n","    # K-fold Cross Validation model procedure\n","    if problemtype=='binary_class' or problemtype=='multiclass':\n","      k_scores = [[],[],[],[],[],[],[],[]]\n","      for k in k_range:\n","        knn = KNeighborsClassifier(n_neighbors=k)\n","        if problemtype=='binary_class':\n","          p = 'precision'\n","          r = 'recall'\n","          f1 = 'f1'\n","        elif problemtype=='multiclass':\n","          f1 = 'f1_weighted'\n","          p = 'precision_weighted'\n","          r = 'recall_weighted'\n","        scores = cross_validate(knn, input_train, target_train, cv=num_folds, scoring=('accuracy', p, r, f1), verbose=verb)\n","        k_scores[0] += [scores['test_accuracy'].mean()]\n","        k_scores[1] += [scores['test_accuracy'].std()]\n","        k_scores[2] += [scores['test_'+p].mean()]\n","        k_scores[3] += [scores['test_'+p].std()]\n","        k_scores[4] += [scores['test_'+r].mean()]\n","        k_scores[5] += [scores['test_'+r].std()]\n","        k_scores[6] += [scores['test_'+f1].mean()]\n","        k_scores[7] += [scores['test_'+f1].std()]\n","      score_dict = ['accuracy','precision','recall',f1]\n","      return k_scores\n","    elif problemtype=='regression':\n","      k_scores = [[],[],[],[]]\n","      for k in k_range:\n","        knn = KNeighborsRegressor(n_neighbors=k)\n","        scores = cross_validate(knn, input_train, target_train, cv=num_folds, scoring=('neg_mean_squared_error', 'r2'), verbose=verb)\n","        k_scores[0] += [scores['test_neg_mean_squared_error'].mean()]\n","        k_scores[1] += [scores['test_neg_mean_squared_error'].std()]\n","        k_scores[2] += [scores['test_r2'].mean()]\n","        k_scores[3] += [scores['test_r2'].std()]\n","      return k_scores\n","\n","  elif kfold_CV==False:\n","    target_test = np.array(target_test.tolist())\n","    if problemtype=='binary_class' or problemtype=='multiclass':\n","      if problemtype=='multiclass':\n","        c='balanced'\n","      else:\n","        c=None\n","      knn = KNeighborsClassifier(n_neighbors=K)\n","      knn.fit(input_train,target_train)\n","      y_pred = knn.predict(input_test)\n","      score = accuracy_score(target_test,y_pred)\n","    elif problemtype=='regression':\n","      knn = KNeighborsRegressor(n_neighbors=K)\n","      knn.fit(input_train,target_train)\n","      y_pred = knn.predict(input_test)\n","      R2 = r2_score(target_test,y_pred)\n","      return R2\n","\n","\n","\n","def rf_mod(dataframe, problemtype, kfold_CV=True, ntree=200, bootstrap=False,\n","           max_features='auto', min_samples_leaf=1, min_samples_split=2,verb=1, n_jobs=None, class_weight=None):\n","  df = dataframe\n","  if problemtype=='regression':\n","      df = df[df['response'].notna()]\n","  df = df.sample(frac=1).reset_index(drop=True)\n","  #samples = len(df['p0'])\n","\n","  verbosity = 1\n","  columns = df.columns.tolist()\n","  samples = len(df[columns[1]])\n","\n","  if problemtype=='multiclass':\n","    LE = LabelEncoder()\n","    numerics=LE.fit(df['class'].tolist())\n","    transformed = LE.transform(df['class'].tolist())\n","    df['class'] = transformed\n","\n","  # Split training and external validation set, establish number of k-folds for internal validation\n","  if samples > 100 and samples <= 500:\n","    dtrain, deval = train_test_split(df, test_size=0.3)\n","    num_folds = 10\n","  elif samples > 500:\n","    dtrain, deval = train_test_split(df, test_size=0.2)\n","    num_folds = 5\n","  elif samples <= 100:\n","    dtrain = df\n","    deval = []\n","    num_folds = samples\n","\n","  # Determine shape of the data\n","  input_shape = (len(columns)-1, )\n","\n","  # Define per-fold score containers\n","  acc_per_fold = []\n","  loss_per_fold = []\n","\n","  # Define the K-fold Cross Validator\n","  kfold = KFold(n_splits=num_folds, shuffle=True)\n","\n","  # Seperate inputs and target values\n","  target_train = dtrain.pop(columns[0])\n","  input_train = dtrain.astype('float64')/dtrain.max().max()\n","  target_test = deval.pop(columns[0])\n","  input_test = deval.astype('float64')/dtrain.max().max()\n","\n","  if kfold_CV==True:\n","    # K-fold Cross Validation model procedure\n","    if problemtype=='binary_class' or problemtype=='multiclass':\n","      rf_scores = [[],[],[],[],[],[],[],[]]\n","      rf = RandomForestClassifier(n_estimators=ntree, min_samples_split=min_samples_split,\n","                                    min_samples_leaf=min_samples_leaf, bootstrap=bootstrap, max_features=max_features, class_weight=class_weight)\n","      if problemtype=='binary_class':\n","        p = 'precision'\n","        r = 'recall'\n","        f1 = 'f1'\n","      elif problemtype=='multiclass':\n","        f1 = 'f1_weighted'\n","        p = 'precision_weighted'\n","        r = 'recall_weighted'\n","      scores = cross_validate(rf, input_train, target_train, cv=num_folds, scoring=('accuracy', p, r, f1),verbose=verb, n_jobs=n_jobs)\n","      rf_scores[0] += [scores['test_accuracy'].mean()]\n","      rf_scores[1] += [scores['test_accuracy'].std()]\n","      rf_scores[2] += [scores['test_'+p].mean()]\n","      rf_scores[3] += [scores['test_'+p].std()]\n","      rf_scores[4] += [scores['test_'+r].mean()]\n","      rf_scores[5] += [scores['test_'+r].std()]\n","      rf_scores[6] += [scores['test_'+f1].mean()]\n","      rf_scores[7] += [scores['test_'+f1].std()]\n","      return rf_scores\n","    elif problemtype=='regression':\n","      rf_scores = [[],[],[],[]]\n","      rf = RandomForestRegressor(n_estimators=ntree, min_samples_split=min_samples_split,\n","                                    min_samples_leaf=min_samples_leaf, bootstrap=bootstrap, max_features=max_features)\n","      scores = cross_validate(rf, input_train, target_train, cv=num_folds, scoring=('neg_mean_squared_error', 'r2'), verbose=verb, n_jobs=n_jobs)\n","      rf_scores[0] += [scores['test_neg_mean_squared_error'].mean()]\n","      rf_scores[1] += [scores['test_neg_mean_squared_error'].std()]\n","      rf_scores[2] += [scores['test_r2'].mean()]\n","      rf_scores[3] += [scores['test_r2'].std()]\n","      return rf_scores\n","\n","  elif kfold_CV==False:\n","    target_test = np.array(target_test.tolist())\n","    if problemtype=='binary_class' or problemtype=='multiclass':\n","      if problemtype=='multiclass':\n","        c='balanced'\n","      else:\n","        c=None\n","      rf = RandomForestClassifier(n_estimators=ntree, min_samples_split=min_samples_split,\n","                                    min_samples_leaf=min_samples_leaf, bootstrap=bootstrap, max_features=max_features)\n","      rf.fit(input_train,target_train)\n","      y_pred = rf.predict(input_test)\n","      print('y_pred:')\n","      print(y_pred)\n","      print('target_test:')\n","      print(target_test)\n","      score = accuracy_score(target_test,y_pred)\n","      return score\n","    elif problemtype=='regression':\n","      rf = RandomForestRegressor(n_estimators=ntree, min_samples_split=min_samples_split,\n","                                    min_samples_leaf=min_samples_leaf, bootstrap=bootstrap, max_features=max_features)\n","      rf.fit(input_train,target_train)\n","      y_pred = rf.predict(input_test)\n","      R2 = r2_score(target_test,y_pred)\n","      return R2\n","\n","\n","\n","def svm_mod(dataframe, problemtype, kfold_CV=True, C=1, kernel='rbf', gamma='scale', verb=1, n_jobs=None):\n","  df = dataframe\n","  if problemtype=='regression':\n","      df = df[df['response'].notna()]\n","  df = df.sample(frac=1).reset_index(drop=True)\n","  #samples = len(df['p0'])\n","\n","  verbosity = 1\n","  columns = df.columns.tolist()\n","  samples = len(df[columns[1]])\n","\n","  if problemtype=='multiclass':\n","    LE = LabelEncoder()\n","    numerics=LE.fit(df['class'].tolist())\n","    transformed = LE.transform(df['class'].tolist())\n","    df['class'] = transformed\n","\n","  # Split training and external validation set, establish number of k-folds for internal validation\n","  if samples > 100 and samples <= 500:\n","    dtrain, deval = train_test_split(df, test_size=0.3)\n","    num_folds = 10\n","  elif samples > 500:\n","    dtrain, deval = train_test_split(df, test_size=0.2)\n","    num_folds = 5\n","  elif samples <= 100:\n","    dtrain = df\n","    deval = []\n","    num_folds = samples\n","\n","  # Determine shape of the data\n","  input_shape = (len(columns)-1, )\n","\n","  # Define per-fold score containers\n","  acc_per_fold = []\n","  loss_per_fold = []\n","\n","  # Define the K-fold Cross Validator\n","  kfold = KFold(n_splits=num_folds, shuffle=True)\n","\n","  # Seperate inputs and target values\n","  target_train = dtrain.pop(columns[0])\n","  input_train = dtrain.astype('float64')/dtrain.max().max()\n","  target_test = deval.pop(columns[0])\n","  input_test = deval.astype('float64')/dtrain.max().max()\n","\n","  if kfold_CV==True:\n","    if problemtype=='binary_class' or problemtype=='multiclass':\n","      sv_scores = [[],[],[],[],[],[],[],[]]\n","      sv = SVC(C=C, kernel=kernel, gamma=gamma, verbose=verb, class_weight='balanced')\n","      if problemtype=='binary_class':\n","        p = 'precision'\n","        r = 'recall'\n","        f1 = 'f1'\n","      elif problemtype=='multiclass':\n","        f1 = 'f1_weighted'\n","        p = 'precision_weighted'\n","        r = 'recall_weighted'\n","      scores = cross_validate(sv, input_train, target_train, cv=num_folds, scoring=('accuracy', p, r, f1),verbose=verb, n_jobs=n_jobs)\n","      sv_scores[0] += [scores['test_accuracy'].mean()]\n","      sv_scores[1] += [scores['test_accuracy'].std()]\n","      sv_scores[2] += [scores['test_'+p].mean()]\n","      sv_scores[3] += [scores['test_'+p].std()]\n","      sv_scores[4] += [scores['test_'+r].mean()]\n","      sv_scores[5] += [scores['test_'+r].std()]\n","      sv_scores[6] += [scores['test_'+f1].mean()]\n","      sv_scores[7] += [scores['test_'+f1].std()]\n","      return sv_scores\n","    elif problemtype=='regression':\n","      sv_scores = [[],[],[],[]]\n","      sv = SVR(C=C, kernel=kernel, gamma=gamma, verbose=verb)\n","      scores = cross_validate(sv, input_train, target_train, cv=num_folds, scoring=('neg_mean_squared_error', 'r2'), verbose=verb, n_jobs=n_jobs)\n","      sv_scores[0] += [scores['test_neg_mean_squared_error'].mean()]\n","      sv_scores[1] += [scores['test_neg_mean_squared_error'].std()]\n","      sv_scores[2] += [scores['test_r2'].mean()]\n","      sv_scores[3] += [scores['test_r2'].std()]\n","      return sv_scores\n","\n","  elif kfold_CV==False:\n","    target_test = np.array(target_test.tolist())\n","    if problemtype=='binary_class' or problemtype=='multiclass':\n","      if problemtype=='multiclass':\n","        c='balanced'\n","      else:\n","        c=None\n","      sv = SVC(C=C, kernel=kernel, gamma=gamma, verbose=verb, class_weight=c)\n","      sv.fit(input_train,target_train)\n","      y_pred = sv.predict(input_test)\n","      score = accuracy_score(target_test,y_pred)\n","      return score\n","    elif problemtype=='regression':\n","      sv = SVR(C=C, kernel=kernel, gamma=gamma, verbose=verb)\n","      sv.fit(input_train,target_train)\n","      y_pred = sv.predict(input_test)\n","      R2 = r2_score(target_test,y_pred)\n","      return R2\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wXuss7j1HHPX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599684281741,"user_tz":180,"elapsed":688,"user":{"displayName":"Kevin Vergara Valenzuela","photoUrl":"","userId":"16931137215428552402"}}},"source":["import numpy as np\n","\n","\n","def plot_confusion_matrix(cm,\n","                          target_names,\n","                          title='Confusion matrix',\n","                          cmap=None,\n","                          normalize=True):\n","    \"\"\"\n","    given a sklearn confusion matrix (cm), make a nice plot\n","\n","    Arguments\n","    ---------\n","    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n","\n","    target_names: given classification classes such as [0, 1, 2]\n","                  the class names, for example: ['high', 'medium', 'low']\n","\n","    title:        the text to display at the top of the matrix\n","\n","    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n","                  see http://matplotlib.org/examples/color/colormaps_reference.html\n","                  plt.get_cmap('jet') or plt.cm.Blues\n","\n","    normalize:    If False, plot the raw numbers\n","                  If True, plot the proportions\n","\n","    Usage\n","    -----\n","    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n","                                                              # sklearn.metrics.confusion_matrix\n","                          normalize    = True,                # show proportions\n","                          target_names = y_labels_vals,       # list of names of the classes\n","                          title        = best_estimator_name) # title of graph\n","\n","    Citiation\n","    ---------\n","    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","\n","    \"\"\"\n","    import matplotlib.pyplot as plt\n","    import numpy as np\n","    import itertools\n","\n","    accuracy = np.trace(cm) / float(np.sum(cm))\n","    misclass = 1 - accuracy\n","\n","    if cmap is None:\n","        cmap = plt.get_cmap('Blues')\n","\n","    plt.figure(figsize=(6, 4))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","\n","    if target_names is not None:\n","        tick_marks = np.arange(len(target_names))\n","        plt.xticks(tick_marks, target_names, rotation=45)\n","        plt.yticks(tick_marks, target_names)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","\n","    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        if normalize:\n","            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","        else:\n","            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=16)\n","\n","\n","    plt.tight_layout()\n","    plt.ylabel('Clase real')\n","    plt.xlabel('Clase predicha\\naccuracy={:0.4f}'.format(accuracy))\n","    plt.show()"],"execution_count":137,"outputs":[]},{"cell_type":"code","metadata":{"id":"vnK5ulyvmMkY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"executionInfo":{"status":"ok","timestamp":1599686692530,"user_tz":180,"elapsed":1181,"user":{"displayName":"Kevin Vergara Valenzuela","photoUrl":"","userId":"16931137215428552402"}},"outputId":"73d4197d-9854-4f85-cdf8-38d039c21b12"},"source":["plot_confusion_matrix(cm           = np.array([[41, 16 ],\n","                                               [8, 65 ]]), \n","                      normalize    = False,\n","                      target_names = ['clase 0', 'clase 1'],\n","                      title        = \"Matriz de confusión para VaxinPad\")"],"execution_count":145,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"wIiQcOohmqQN","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}